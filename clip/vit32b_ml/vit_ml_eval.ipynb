{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "copyrighted-harmony",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "from PIL import Image, ImageFile\n",
    "import glob\n",
    "import torch\n",
    "import pickle\n",
    "import zipfile\n",
    "from IPython.display import display\n",
    "from IPython.display import Image as IPImage\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_value(dict_obj, key, value):\n",
    "    # Check if key exist in dict or not\n",
    "    if key in dict_obj:\n",
    "        # Key exist in dict.\n",
    "        # Check if type of value of key is list or not\n",
    "        if not isinstance(dict_obj[key], list):\n",
    "            # If type is not list then make it list\n",
    "            dict_obj[key] = [dict_obj[key]]\n",
    "        # Append the value in list\n",
    "        dict_obj[key].append(value)\n",
    "    else:\n",
    "        # As key is not in dict,\n",
    "        # so, add key-value pair\n",
    "        dict_obj[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "strategic-mayor",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = pprint.PrettyPrinter(indent=4, width=200, depth=None, stream=None, compact=False, sort_dicts=False)\n",
    "\n",
    "img_folder = 'images_30k/'\n",
    "\n",
    "test_df = pd.read_csv(f\"test_df_from_30k.csv\")\n",
    "\n",
    "captions_w_fnames = test_df.to_dict('records')\n",
    "\n",
    "d_imgs_w_texts = {} \n",
    "for e in captions_w_fnames:\n",
    "    append_value(d_imgs_w_texts, e['image'], e['caption'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>caption_number</th>\n",
       "      <th>caption</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001545525.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>Két férfi Németországban egyszerre ugrott át a...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001545525.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Két fiatal ugrál át az út menti korláton éjszaka.</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001545525.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>Rúdon táncoló fiúk az éjszaka közepén.</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001545525.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>Két ing nélküli férfi ugrál át a sínen.</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001545525.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>két srác együtt ugrott át egy kapun</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31780</th>\n",
       "      <td>99804383.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>Egy idősebb, szemüveges busker egy keleti vonó...</td>\n",
       "      <td>31781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31781</th>\n",
       "      <td>99804383.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Ez egy férfi egy bolt előtt fellép egy kisfiúv...</td>\n",
       "      <td>31781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31782</th>\n",
       "      <td>99804383.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>Egy idősebb ázsiai férfi hangszeren játszik eg...</td>\n",
       "      <td>31781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31783</th>\n",
       "      <td>99804383.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>Egy idős férfi ül a kirakat előtt egy fiatal f...</td>\n",
       "      <td>31781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31784</th>\n",
       "      <td>99804383.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>Egy idős úriember hangszeren játszik a járdán ...</td>\n",
       "      <td>31781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31785 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                image  caption_number  \\\n",
       "0      1001545525.jpg               0   \n",
       "1      1001545525.jpg               1   \n",
       "2      1001545525.jpg               2   \n",
       "3      1001545525.jpg               3   \n",
       "4      1001545525.jpg               4   \n",
       "...               ...             ...   \n",
       "31780    99804383.jpg               0   \n",
       "31781    99804383.jpg               1   \n",
       "31782    99804383.jpg               2   \n",
       "31783    99804383.jpg               3   \n",
       "31784    99804383.jpg               4   \n",
       "\n",
       "                                                 caption     id  \n",
       "0      Két férfi Németországban egyszerre ugrott át a...      9  \n",
       "1      Két fiatal ugrál át az út menti korláton éjszaka.      9  \n",
       "2                 Rúdon táncoló fiúk az éjszaka közepén.      9  \n",
       "3                Két ing nélküli férfi ugrál át a sínen.      9  \n",
       "4                    két srác együtt ugrott át egy kapun      9  \n",
       "...                                                  ...    ...  \n",
       "31780  Egy idősebb, szemüveges busker egy keleti vonó...  31781  \n",
       "31781  Ez egy férfi egy bolt előtt fellép egy kisfiúv...  31781  \n",
       "31782  Egy idősebb ázsiai férfi hangszeren játszik eg...  31781  \n",
       "31783  Egy idős férfi ül a kirakat előtt egy fiatal f...  31781  \n",
       "31784  Egy idős úriember hangszeren játszik a járdán ...  31781  \n",
       "\n",
       "[31785 rows x 4 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "adjacent-encyclopedia",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ftfy or spacy is not installed using BERT BasicTokenizer instead of ftfy.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images: 6357\n",
      "6356\r"
     ]
    }
   ],
   "source": [
    "# Now, we need to compute the embeddings\n",
    "# To speed things up, we destribute pre-computed embeddings\n",
    "# Otherwise you can also encode the images yourself.\n",
    "# To encode an image, you can use the following code:\n",
    "# from PIL import Image\n",
    "# img_emb = model.encode(Image.open(filepath))\n",
    "\n",
    "# Here we load the multilingual CLIP model. Note, this model can only encode text.\n",
    "# If you need embeddings for images, you must load the 'clip-ViT-B-32' model\n",
    "text_model = SentenceTransformer('clip-ViT-B-32-multilingual-v1')\n",
    "\n",
    "#For embedding images, we need the non-multilingual CLIP model\n",
    "img_model = SentenceTransformer('clip-ViT-B-32')\n",
    "\n",
    "#img_names = list(glob.glob(f'{img_folder}*.jpg'))\n",
    "test_imgs = list(d_imgs_w_texts.keys())\n",
    "\n",
    "captions = list(test_df['caption'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_embs = np.empty([len(test_imgs), 512])\n",
    "for idx, file in enumerate(test_imgs):\n",
    "    img = Image.open(img_folder+file)\n",
    "    print(idx,end='\\r')\n",
    "    img_embs[idx] = img_model.encode(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embeddings = text_model.encode(captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matches_from_img_to_texts(text_embeddings, image_fn, captions, n=5):\n",
    "\n",
    "    img = Image.open(img_folder+image_fn)\n",
    "    image_embedding = img_model.encode(img)\n",
    "\n",
    "    image_embedding_t = torch.from_numpy(image_embedding)\n",
    "    text_embeddings_t = torch.from_numpy(text_embeddings)\n",
    "\n",
    "    text_embeddings_n = F.normalize(text_embeddings_t, p=2, dim=-1)   # all caption \n",
    "    image_embedding_n = F.normalize(image_embedding_t, p=2, dim=-1)   # just one image\n",
    "\n",
    "    dot_similarity = image_embedding_n @ text_embeddings_n.T\n",
    "\n",
    "    values, indices = torch.topk(dot_similarity.squeeze(0), n)\n",
    "    \n",
    "    matches = [captions[idx] for idx in indices]\n",
    "\n",
    "    return matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_cnt = len(d_imgs_w_texts)\n",
    "caption_cnt = img_cnt*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt=0\n",
    "res_sum = 0\n",
    "cnt_when_not_zero=0\n",
    "\n",
    "for k,v  in d_imgs_w_texts.items():\n",
    "    #print(cnt)\n",
    "    res=0\n",
    "    # k = img_fname v = list_of_captions_for_the_img\n",
    "    zs=find_matches_from_img_to_texts(text_embeddings, k, captions, n=5)\n",
    "    #print(\"expected: \",k, v)\n",
    "    #print(\"got: \", zs)\n",
    "    for text in zs:\n",
    "        if(text in v): res+=1\n",
    "    #print(f'{res}/5')\n",
    "    if res != 0 : cnt_when_not_zero+=1 \n",
    "    res_sum += res\n",
    "    cnt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3370 / 6357\n",
      "5779 / 31785\n"
     ]
    }
   ],
   "source": [
    "print(cnt_when_not_zero, '/', img_cnt)\n",
    "print(res_sum ,'/', caption_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it works the same way as the search method from huggingface\n",
    "def find_matches_from_text_to_img(image_embeddings, caption, image_filenames, n=5):\n",
    "\n",
    "    text_embedding = text_model.encode(caption)\n",
    "\n",
    "    image_embeddings_t = torch.from_numpy(image_embeddings).float()\n",
    "    text_embedding_t = torch.from_numpy(text_embedding).float()\n",
    "\n",
    "    image_embeddings_n = F.normalize(image_embeddings_t, p=2, dim=-1)\n",
    "    text_embedding_n = F.normalize(text_embedding_t, p=2, dim=-1)\n",
    "\n",
    "    dot_similarity = text_embedding_n @ image_embeddings_n.T\n",
    "    values, indices = torch.topk(dot_similarity.squeeze(0), n)\n",
    "    print(values)\n",
    "    print(indices)\n",
    "    matches = [image_filenames[idx] for idx in indices]\n",
    "    \n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_matches_from_text_to_img(img_embs, \"két srác együtt ugrott át egy kapun\", test_imgs, n=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a7dbb88c84ecda04e2dfa8176cb6708abf8c95c32934f510df16d1a1f4945387"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
