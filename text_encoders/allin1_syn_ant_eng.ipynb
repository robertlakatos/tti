{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# all text encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4, width=200, depth=None, stream=None, compact=False, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('../pdf_to_dictionary/english_syn_ant.json', encoding='utf-8') as f:\n",
    "    d = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def my_cosine_similarity(A, B):\n",
    "    return np.dot(A,B)/(norm(A)*norm(B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make smaller test dict\n",
    "d_keys_li=list(d.keys())\n",
    "smaller_dict={}\n",
    "for i in range(0,10):\n",
    "    smaller_dict[d_keys_li[i]]=d[d_keys_li[i]]\n",
    "# pp.pprint(smaller_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d - full test disctionary\n",
    "# smaller_dict - 10 key dictionary\n",
    "# DICT = smaller_dict\n",
    "DICT = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aback ['backwards', 'rearwards', 'aft', 'abaft', 'astern', 'behind', 'back'] ['onwards', 'forwards', 'ahead', 'before', 'afront', 'beyond', 'afore']\n"
     ]
    }
   ],
   "source": [
    "for baseword,v in DICT.items():\n",
    "    print(baseword,v[\"syn\"],v[\"ant\"])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_res(tokenizer, model):\n",
    "    sum_syn=0\n",
    "    sum_ant=0\n",
    "    cnt_syn=0\n",
    "    cnt_ant=0\n",
    "\n",
    "    for baseword,v in DICT.items():\n",
    "        encoded_input_base=tokenizer(baseword,return_tensors='pt')\n",
    "        output_base = model(**encoded_input_base)\n",
    "        embedded_base=output_base[0][0][-1]\n",
    "\n",
    "        for synonym in v[\"syn\"]:\n",
    "            encoded_input_synonym=tokenizer(synonym,return_tensors='pt')\n",
    "            output_synonym = model(**encoded_input_synonym)            \n",
    "            embedded_synonym=output_synonym[0][0][-1]            \n",
    "            sim_syn=my_cosine_similarity(embedded_base.detach().numpy(),embedded_synonym.detach().numpy())\n",
    "            sum_syn=sum_syn+sim_syn\n",
    "            cnt_syn=cnt_syn+1\n",
    "\n",
    "        for antonym in v[\"ant\"]:\n",
    "            encoded_input_antonym=tokenizer(antonym, return_tensors='pt')\n",
    "            output_antonym = model(**encoded_input_antonym)            \n",
    "            embedded_antonym=output_antonym[0][0][-1]            \n",
    "            sim_ant=my_cosine_similarity(embedded_base.detach().numpy(),embedded_antonym.detach().numpy())\n",
    "            sum_ant=sum_ant+sim_ant\n",
    "            cnt_ant=cnt_ant+1\n",
    "\n",
    "        print(cnt_syn, cnt_ant, end=\"\\r\")\n",
    "           \n",
    "    print(\"syn\", sum_syn/cnt_syn)\n",
    "    print(\"ant\", sum_ant/cnt_ant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_res_sentiment(tokenizer, model):\n",
    "    sum_syn=0\n",
    "    sum_ant=0\n",
    "    cnt_syn=0\n",
    "    cnt_ant=0\n",
    "\n",
    "    for baseword,v in DICT.items():\n",
    "        encoded_input_base=tokenizer(baseword,return_tensors='pt')\n",
    "        output_base = model(**encoded_input_base)\n",
    "        embedded_base=output_base[0][-1]\n",
    "\n",
    "        for synonym in v[\"syn\"]:\n",
    "            encoded_input_synonym=tokenizer(synonym,return_tensors='pt')\n",
    "            output_synonym = model(**encoded_input_synonym)            \n",
    "            embedded_synonym=output_synonym[0][-1]\n",
    "            sim_syn=my_cosine_similarity(embedded_base.detach().numpy(),embedded_synonym.detach().numpy())\n",
    "            sum_syn=sum_syn+sim_syn\n",
    "            cnt_syn=cnt_syn+1\n",
    "\n",
    "        for antonym in v[\"ant\"]:\n",
    "            encoded_input_antonym=tokenizer(antonym,return_tensors='pt')\n",
    "            output_antonym = model(**encoded_input_antonym)            \n",
    "            embedded_antonym=output_antonym[0][-1]\n",
    "            sim_ant=my_cosine_similarity(embedded_base.detach().numpy(),embedded_antonym.detach().numpy())\n",
    "            sum_ant=sum_ant+sim_ant\n",
    "            cnt_ant=cnt_ant+1\n",
    "\n",
    "    \n",
    "        print(cnt_syn, cnt_ant, end=\"\\r\")\n",
    "\n",
    "    print(\"syn\", sum_syn/cnt_syn)\n",
    "    print(\"ant\", sum_ant/cnt_ant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_res_xlm100(tokenizer,model):\n",
    "    sum_syn=0\n",
    "    sum_ant=0\n",
    "    cnt_syn=0\n",
    "    cnt_ant=0\n",
    "\n",
    "    language_id_hu = tokenizer.lang2id[\"hu\"]\n",
    "\n",
    "    for baseword,v in DICT.items():\n",
    "        base_input_ids = torch.tensor([tokenizer.encode(baseword)])\n",
    "        base_lang =  torch.tensor([language_id_hu] * base_input_ids.shape[1])\n",
    "        base_lang = base_lang.view(1, -1)\n",
    "        output_base = model(base_input_ids, langs=base_lang)\n",
    "        embedded_base=output_base[0][0][-1].tolist()\n",
    "\n",
    "        for synonym in v[\"syn\"]:\n",
    "            syn_input_ids = torch.tensor([tokenizer.encode(synonym)])\n",
    "            syn_lang =  torch.tensor([language_id_hu] * syn_input_ids.shape[1])\n",
    "            syn_lang = syn_lang.view(1, -1)\n",
    "            output_syn = model(syn_input_ids, langs=syn_lang)            \n",
    "            embedded_syn=output_syn[0][0][-1].tolist()\n",
    "            sim_syn=my_cosine_similarity(embedded_base,embedded_syn)\n",
    "            sum_syn=sum_syn+sim_syn\n",
    "            cnt_syn=cnt_syn+1\n",
    "\n",
    "        for antonym in v[\"ant\"]:\n",
    "            ant_input_ids = torch.tensor([tokenizer.encode(antonym)])\n",
    "            ant_lang =  torch.tensor([language_id_hu] * ant_input_ids.shape[1])\n",
    "            ant_lang = ant_lang.view(1, -1)\n",
    "            output_ant = model(ant_input_ids, langs=ant_lang)            \n",
    "            embedded_ant=output_ant[0][0][-1].tolist()\n",
    "            sim_ant=my_cosine_similarity(embedded_base,embedded_ant)\n",
    "            sum_ant=sum_ant+sim_ant\n",
    "            cnt_ant=cnt_ant+1\n",
    "\n",
    "        print(cnt_syn, cnt_ant, end=\"\\r\")\n",
    "\n",
    "    print(\"syn\", sum_syn/cnt_syn)\n",
    "    print(\"ant\", sum_ant/cnt_ant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\L0021\\Anaconda3\\envs\\test\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7567041850302905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.0719,  0.0129,  0.1084,  ..., -0.0177,  0.0109, -0.0168],\n",
       "         [ 0.0741,  0.4268,  0.2884,  ..., -0.1076,  0.2218, -0.0412],\n",
       "         [-0.3344, -0.1295, -0.0935,  ...,  0.2953, -0.3330, -0.4336],\n",
       "         [-0.1503, -0.7483, -0.0366,  ...,  0.0960,  0.3610,  0.2214],\n",
       "         [ 0.0396,  0.5546,  0.1998,  ..., -0.1647, -0.0531, -0.2683],\n",
       "         [-0.8048,  1.0132,  0.5755,  ...,  0.7749, -0.1809, -1.0477]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 1.5644e-01, -7.0881e-04,  2.2195e-01,  1.5884e-01,  1.9606e-01,\n",
       "          4.1540e-01,  1.5336e-01, -1.3350e-01, -1.5227e-01,  2.8029e-01,\n",
       "         -2.2688e-01, -2.1446e-01,  2.6676e-01, -1.9476e-01, -2.4235e-01,\n",
       "          1.0252e-01,  1.7405e-01,  1.2447e-01,  2.1441e-01,  9.2159e-02,\n",
       "         -3.6972e-02, -3.6511e-02,  8.7314e-02, -7.4431e-03,  2.7466e-01,\n",
       "         -1.7619e-01,  2.4513e-01,  1.0325e-01,  3.8374e-01,  3.1987e-01,\n",
       "          2.3075e-01,  2.3752e-01,  2.0864e-01, -1.0451e-01,  1.8358e-01,\n",
       "          6.8261e-02, -2.0091e-02,  1.1370e-01,  2.2195e-01,  5.9262e-02,\n",
       "          1.6852e-01,  4.4490e-01,  1.3616e-01, -1.1630e-01, -3.1842e-01,\n",
       "          2.2589e-01, -1.7202e-01, -9.7308e-02,  9.9999e-01,  2.1156e-01,\n",
       "          1.3941e-01, -1.5599e-01,  1.2079e-01, -2.6029e-01,  2.2186e-01,\n",
       "          9.9999e-01, -3.2498e-01, -2.6794e-01,  5.5690e-02, -9.3815e-02,\n",
       "         -2.1551e-01,  4.7572e-02,  2.9010e-01,  1.2794e-01, -8.2600e-02,\n",
       "          5.9717e-02, -1.1013e-01,  3.6206e-01,  1.3375e-02,  8.9478e-02,\n",
       "          6.6176e-02, -1.2623e-01,  2.2325e-01,  3.0252e-01, -1.7953e-01,\n",
       "          5.9037e-02, -2.1563e-01, -1.4112e-01, -1.6815e-01,  2.2725e-01,\n",
       "          1.7989e-01,  7.0290e-02, -2.8306e-01,  2.4188e-01, -1.3084e-01,\n",
       "         -2.5592e-01, -2.6663e-01, -5.7038e-02,  1.7217e-01, -1.6645e-01,\n",
       "          1.5372e-01, -9.6871e-02, -6.7760e-02, -9.2857e-02,  2.1455e-01,\n",
       "         -1.5819e-01, -3.1514e-01, -1.0451e-01,  1.1107e-01, -2.4458e-01,\n",
       "         -5.4106e-02,  1.6028e-01,  6.2564e-02,  7.1641e-02,  2.1166e-01,\n",
       "          2.4960e-01, -2.6447e-01, -1.7978e-01,  6.7962e-02,  1.8007e-03,\n",
       "         -2.3001e-01,  1.7778e-02,  4.1909e-01,  2.3347e-01,  9.5314e-02,\n",
       "          4.0090e-03, -1.7251e-01, -7.3483e-01, -6.1126e-02,  1.0939e-01,\n",
       "         -4.8170e-02,  9.9999e-01, -1.7517e-01, -1.9023e-01,  1.4761e-01,\n",
       "         -2.5676e-01, -1.2294e-01,  2.1187e-01, -2.5202e-01,  3.2408e-01,\n",
       "         -2.9416e-01, -4.9719e-02, -2.7673e-01,  8.1998e-02, -2.2504e-01,\n",
       "          2.5045e-01,  1.0330e-01, -1.5059e-01,  4.5902e-02, -2.5651e-01,\n",
       "          8.0176e-02,  1.9140e-01,  1.1070e-01,  1.2563e-01,  2.1415e-01,\n",
       "         -2.4920e-01, -1.1878e-01, -1.0131e-03, -7.8665e-02,  2.3192e-01,\n",
       "         -3.3168e-01, -2.0576e-01,  3.9340e-02, -2.0820e-01, -4.2359e-02,\n",
       "         -3.0532e-01,  1.5748e-01, -2.9273e-01,  2.5130e-01,  9.9979e-02,\n",
       "         -2.2890e-01,  2.3877e-01,  2.5850e-01,  1.1664e-01,  1.6883e-01,\n",
       "         -2.1990e-01,  7.1549e-01, -1.4920e-01,  2.1375e-01, -2.6542e-01,\n",
       "         -8.2091e-02,  1.0703e-01,  2.2493e-01,  1.6130e-01, -1.9549e-01,\n",
       "         -2.7858e-01,  2.1713e-01, -7.4518e-02,  1.2153e-01, -4.5060e-01,\n",
       "          1.1860e-01, -3.6057e-01, -1.4486e-01,  1.4447e-01, -4.3005e-03,\n",
       "          5.2847e-02, -2.2709e-01, -6.2512e-01, -8.7073e-02, -2.0966e-01,\n",
       "          1.1727e-01,  1.6847e-01,  1.5446e-01,  2.5917e-01,  2.2246e-01,\n",
       "          3.6545e-02, -2.2021e-01, -1.8555e-01, -7.1852e-02,  9.7336e-02,\n",
       "         -4.6029e-01,  1.0360e-01, -6.1015e-02, -1.9195e-01, -2.6551e-01,\n",
       "          2.8658e-01, -1.9497e-01,  9.9999e-01,  1.2815e-01, -1.5765e-01,\n",
       "          1.5194e-01, -1.1417e-01, -1.9275e-02, -5.6774e-02, -2.0552e-01,\n",
       "          1.1646e-01,  1.4046e-01, -8.9523e-02,  1.8356e-01, -2.6531e-01,\n",
       "         -2.3838e-01,  6.3766e-01,  2.8606e-01, -2.2768e-01, -6.1198e-02,\n",
       "         -2.8623e-01, -1.3430e-02, -3.1472e-01,  2.0494e-01, -9.0237e-02,\n",
       "          2.9207e-02,  1.4008e-01,  3.8478e-01, -2.6758e-01,  1.4405e-01,\n",
       "         -3.2785e-01, -2.6567e-01, -2.2985e-01, -4.3439e-01, -1.2761e-01,\n",
       "          9.2057e-02,  1.9439e-01, -1.3197e-01, -3.3729e-02,  2.8650e-01,\n",
       "         -1.9785e-01,  1.2162e-01, -1.7614e-01, -2.4455e-01, -1.5578e-01,\n",
       "          7.8994e-02, -9.7467e-02, -1.2161e-01,  3.1134e-01,  1.7227e-01,\n",
       "          1.2532e-01, -1.2651e-01, -2.1755e-01,  4.4388e-02,  1.8627e-01,\n",
       "          1.7656e-01,  3.9646e-02, -1.5133e-01, -1.0279e-01,  2.6834e-02,\n",
       "         -2.5750e-01,  1.2650e-01,  7.6051e-02, -1.0018e-01,  1.0842e-01,\n",
       "          3.7404e-01,  1.8739e-01, -9.6616e-02,  3.2465e-01, -4.1770e-01,\n",
       "          8.3484e-02,  2.3054e-01, -2.5261e-01,  2.5682e-01,  1.7212e-01,\n",
       "          1.6558e-02, -1.3891e-01,  8.6345e-02, -1.9238e-01,  6.9516e-02,\n",
       "          2.4274e-01,  6.9662e-02, -2.0535e-01,  1.3842e-01,  3.3547e-01,\n",
       "          1.0914e-01, -1.6182e-01, -1.3818e-01,  6.5839e-02,  1.9553e-01,\n",
       "         -2.0265e-01,  2.8828e-01,  1.0246e-01, -1.5769e-01, -1.8973e-01,\n",
       "          1.1604e-01, -1.7282e-01, -1.5243e-01, -3.7145e-02,  2.3822e-01,\n",
       "          2.3613e-01, -1.9292e-01, -1.3164e-01, -1.6519e-01, -9.4786e-02,\n",
       "          1.1669e-01, -1.8735e-01, -2.6788e-01,  2.5041e-01, -3.6788e-01,\n",
       "          1.6362e-01,  1.8157e-01, -3.2109e-01, -2.6914e-02, -1.5090e-01,\n",
       "          1.2722e-01,  9.9999e-01, -2.4820e-01, -1.8263e-01, -9.9999e-01,\n",
       "         -4.8109e-01, -2.6457e-01,  2.8606e-01,  1.5014e-01, -2.7096e-01,\n",
       "         -5.3204e-02,  1.8975e-01, -1.3944e-01, -1.9357e-01,  1.8233e-01,\n",
       "          4.1197e-01, -2.4426e-01,  1.4983e-01,  9.5079e-02,  1.2756e-02,\n",
       "          1.1038e-01, -9.9999e-01, -8.7669e-02, -5.0590e-04,  3.6870e-02,\n",
       "         -7.5830e-02, -2.1522e-01, -2.1752e-01, -9.7098e-02,  1.6937e-01,\n",
       "          2.1636e-01,  2.0625e-01, -1.1701e-01, -2.5586e-01, -3.6925e-01,\n",
       "          1.6738e-01, -1.1567e-01,  6.3736e-02, -2.2279e-01, -2.4314e-01,\n",
       "          1.0704e-01,  1.6088e-01,  3.0327e-02,  3.0140e-01, -1.1462e-01,\n",
       "          1.7156e-01, -2.1641e-01,  9.9999e-01,  1.7919e-01, -1.6911e-01,\n",
       "          9.9999e-01,  2.3626e-01, -1.9012e-02, -4.4899e-01,  9.4443e-02,\n",
       "          9.1382e-02,  9.9999e-01,  1.1705e-01, -2.6779e-01, -1.2709e-01,\n",
       "          2.1049e-02,  2.8252e-01,  4.1321e-01, -1.0370e-02, -9.9999e-01,\n",
       "          1.1930e-01,  1.9241e-01,  1.3633e-02, -6.1545e-02,  9.9999e-01,\n",
       "         -1.3360e-01, -1.5853e-01,  1.1812e-01,  3.4269e-01,  1.6674e-01,\n",
       "          3.7894e-01,  2.2241e-01, -6.1074e-02, -1.6947e-01, -1.3353e-01,\n",
       "         -1.2764e-01, -3.5838e-01, -1.6491e-01,  8.3062e-02, -1.6210e-01,\n",
       "         -7.4543e-02, -2.5387e-01, -2.9455e-02, -3.1801e-02,  9.9999e-01,\n",
       "         -1.6581e-02,  1.6941e-01,  7.4351e-02,  1.4006e-01,  8.4324e-02,\n",
       "         -5.5202e-02, -6.3835e-02, -3.0571e-01,  2.7477e-01, -1.9665e-01,\n",
       "          1.6252e-01,  4.4552e-02,  8.4564e-02, -1.9013e-01, -1.0088e-01,\n",
       "         -2.1557e-01,  1.7055e-01,  8.3381e-02,  3.9037e-01,  1.8828e-01,\n",
       "         -1.4749e-01, -1.1858e-01,  1.4499e-01, -2.3163e-02,  2.2826e-01,\n",
       "         -1.3809e-01,  9.9999e-01,  2.4350e-01, -1.5336e-01, -1.7846e-02,\n",
       "         -9.0539e-02, -2.4021e-01, -1.4293e-01, -2.7174e-01,  5.6384e-01,\n",
       "          1.0551e-01,  6.4930e-02,  1.2475e-01,  3.2126e-01, -6.5560e-02,\n",
       "         -1.1031e-01,  1.2174e-01,  7.5368e-02,  3.8392e-02, -3.1520e-01,\n",
       "         -9.9999e-01, -2.7124e-01,  1.6652e-01, -3.3359e-01, -2.1895e-01,\n",
       "         -2.9955e-03, -3.1869e-01, -4.9305e-02, -4.7380e-02,  3.8382e-03,\n",
       "          5.7384e-02, -2.3999e-01, -1.8345e-01,  1.3237e-01, -1.8297e-01,\n",
       "         -1.9649e-01,  1.8323e-01,  2.8467e-01,  2.5437e-01, -8.1301e-02,\n",
       "          2.6614e-01,  1.7559e-01, -5.0125e-02,  1.6957e-01, -9.2382e-02,\n",
       "          9.4678e-02, -3.0318e-01, -3.1962e-01, -1.8303e-01, -2.0972e-01,\n",
       "          1.8280e-01, -2.3351e-01, -6.8533e-02,  1.1103e-01, -2.2242e-01,\n",
       "          2.0750e-01,  1.6500e-01, -1.7468e-02, -1.8464e-01,  7.8741e-02,\n",
       "         -8.5270e-02,  1.1556e-01, -3.4911e-01,  2.2009e-01, -1.5896e-03,\n",
       "          1.9098e-01, -1.5459e-01, -6.4582e-02,  1.8627e-01, -2.1238e-01,\n",
       "          1.6594e-01,  1.5057e-01,  1.7402e-01, -1.1474e-01, -2.4278e-01,\n",
       "         -3.7093e-02,  5.4146e-02,  2.6287e-01,  1.2934e-01, -1.9626e-01,\n",
       "         -1.4327e-01, -1.6074e-01, -2.4548e-01, -7.1239e-03,  1.6517e-02,\n",
       "         -9.9999e-01, -9.0353e-03, -2.0622e-01, -2.0378e-01,  2.3353e-01,\n",
       "          9.8246e-02,  3.0996e-01, -8.7128e-03, -5.3149e-01,  2.9867e-01,\n",
       "         -1.2856e-01, -2.5170e-01, -2.3093e-02,  1.0440e-01, -2.1759e-02,\n",
       "          8.0711e-02, -9.9999e-01,  8.4927e-02,  1.5361e-01, -2.1273e-01,\n",
       "          1.6950e-01,  1.7957e-01, -4.3334e-02,  1.0595e-01, -9.8885e-02,\n",
       "          8.5396e-01,  1.0919e-01,  8.5835e-02, -1.0926e-01, -2.9740e-02,\n",
       "         -2.2543e-01, -2.9119e-01, -2.1368e-01,  1.4781e-01, -2.5723e-03,\n",
       "          1.6162e-01, -2.2950e-01,  2.5807e-01,  5.5826e-02,  4.1923e-01,\n",
       "          2.3188e-01, -1.2878e-01,  7.3158e-02, -1.3648e-01,  2.0365e-01,\n",
       "          9.4916e-02,  2.8250e-01, -1.0116e-01, -4.0708e-02,  1.1433e-01,\n",
       "         -1.2835e-01,  1.2894e-01,  1.6289e-01,  4.5961e-02,  3.4679e-01,\n",
       "          1.9027e-01,  2.3114e-01, -1.0397e-01, -1.4885e-01,  1.5078e-01,\n",
       "          1.2362e-01, -2.7757e-01,  6.0650e-02,  9.9412e-02, -2.5995e-04,\n",
       "         -5.1431e-02,  1.0283e-01, -2.0328e-01,  8.4081e-02, -2.6921e-01,\n",
       "         -2.3895e-01, -1.9158e-01,  1.2816e-01, -8.0368e-02, -2.8274e-01,\n",
       "          2.1423e-01, -1.9126e-01, -2.8280e-01, -1.3170e-01,  5.1119e-04,\n",
       "          1.3818e-01, -1.6544e-01, -1.4499e-01,  1.3618e-01,  2.8919e-01,\n",
       "          5.8410e-02,  2.0073e-01,  2.1303e-01, -7.4961e-02,  2.5079e-02,\n",
       "          1.9446e-01, -1.9706e-01, -3.2065e-01,  2.0481e-01,  1.1334e-01,\n",
       "          6.3416e-02,  1.9359e-01,  2.2152e-02, -2.5897e-01,  2.0263e-01,\n",
       "          7.6391e-02, -6.6354e-02, -1.5077e-01,  1.5444e-01, -1.2184e-01,\n",
       "         -1.2120e-01,  1.8321e-01, -9.9999e-01,  2.4745e-02, -8.0226e-02,\n",
       "         -1.1003e-01,  3.2629e-01,  2.9140e-01,  1.9079e-01,  1.4815e-01,\n",
       "         -5.1488e-02, -2.3966e-01, -2.9522e-01, -5.9546e-02, -9.9588e-02,\n",
       "         -5.0861e-01,  1.0556e-01, -4.4945e-03, -9.0008e-02,  1.8019e-01,\n",
       "         -3.6725e-01, -2.9294e-01, -2.0774e-01, -3.4098e-02,  2.4312e-01,\n",
       "          8.8437e-02,  9.9073e-02, -3.1423e-01, -1.0624e-01, -6.8093e-02,\n",
       "         -3.3742e-01, -2.9763e-01,  2.6506e-01,  2.8266e-01,  2.4559e-01,\n",
       "         -5.4795e-01,  2.4314e-01, -1.8542e-01, -1.2857e-01,  1.1907e-01,\n",
       "          1.7102e-01,  7.0881e-02, -1.7294e-01,  2.9746e-01, -1.2555e-01,\n",
       "         -2.3310e-01,  1.1672e-01, -2.9761e-01,  1.8422e-01, -8.1044e-01,\n",
       "          2.1925e-01,  1.4780e-01,  3.9473e-01, -2.0101e-01,  2.4009e-01,\n",
       "          1.3327e-01,  8.4527e-02,  1.5765e-02,  2.0406e-01,  3.4554e-02,\n",
       "          3.4545e-01, -1.1224e-01,  2.3508e-01,  3.9279e-01, -9.9999e-01,\n",
       "         -7.5037e-02, -1.3875e-01, -1.7533e-01, -9.9999e-01, -1.2408e-01,\n",
       "          1.7552e-01,  9.0664e-02,  1.6971e-01, -4.1553e-02,  1.9190e-01,\n",
       "          2.5241e-01, -1.7890e-01, -1.7012e-01,  1.7555e-01, -2.5401e-01,\n",
       "         -9.5962e-03,  2.4052e-01, -2.5884e-01, -2.1381e-01,  1.6259e-01,\n",
       "          2.6111e-01,  3.9278e-01, -1.5967e-02, -5.0717e-01,  4.5883e-01,\n",
       "         -7.9050e-02, -1.3658e-01, -4.3003e-01, -1.9583e-01,  2.4448e-01,\n",
       "         -2.5351e-02,  1.2138e-01,  1.5538e-01,  3.0448e-01, -1.2488e-01,\n",
       "         -2.0861e-01,  4.7130e-02, -1.5326e-01,  3.2589e-01,  1.2334e-01,\n",
       "          1.6504e-01, -6.9935e-02,  4.8720e-01, -2.4894e-01, -1.5661e-01,\n",
       "          1.9738e-02, -3.1643e-02,  3.7209e-01, -1.7416e-01, -1.9236e-01,\n",
       "          3.9116e-01, -2.3267e-01, -1.2488e-01,  2.3979e-01,  1.1237e-01,\n",
       "         -2.5332e-01, -1.1121e-01, -1.3185e-01,  3.5858e-01, -9.9999e-01,\n",
       "         -5.3958e-02, -1.6921e-01,  2.1492e-01,  5.0196e-02, -1.2412e-01,\n",
       "          8.3474e-01,  3.3459e-01,  9.4898e-02,  2.2244e-01, -2.7007e-01,\n",
       "         -1.2218e-01, -2.4856e-01,  1.7219e-01,  1.2873e-01, -5.8175e-02,\n",
       "          3.4005e-02, -1.7938e-01, -1.3647e-01]], grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bert-base-multilingual-uncased\n",
    "# Run time: 21m\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-multilingual-uncased\")\n",
    "\n",
    "get_avg_res(tokenizer,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6126954996837073\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.0352, -0.0060,  0.3350,  ...,  0.2529,  0.3051,  0.3122],\n",
       "         [-0.4581, -0.3785,  0.2395,  ...,  0.4396,  0.6502,  0.4630],\n",
       "         [ 0.0305, -0.5363,  0.1183,  ...,  0.1776,  0.3533,  0.5092],\n",
       "         [-0.0905, -0.9662,  1.0015,  ...,  0.0550,  0.5291,  0.5825],\n",
       "         [-0.0639, -0.1973,  1.1161,  ...,  0.4076,  0.0489,  0.4222],\n",
       "         [-0.0270, -0.0967,  0.9523,  ...,  0.1293,  0.4513,  0.7500]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 1.8316e-01, -1.4452e-01,  2.4417e-01, -2.9282e-02, -8.9008e-03,\n",
       "          3.3721e-01,  1.0858e-01,  2.7783e-01, -3.1669e-01,  1.9912e-01,\n",
       "          7.7042e-02, -6.6136e-02, -8.7563e-02, -1.9693e-01,  2.8700e-01,\n",
       "         -1.2130e-01,  3.6513e-01,  3.8714e-02,  6.1837e-02, -2.7817e-01,\n",
       "         -9.9997e-01, -3.0202e-01, -1.9889e-01, -1.4710e-01, -3.0429e-01,\n",
       "          1.0936e-01,  3.7754e-02,  1.2235e-01,  1.3897e-01, -1.5806e-01,\n",
       "         -1.3935e-01, -9.9997e-01,  4.8610e-01,  3.6769e-01,  1.7805e-01,\n",
       "         -2.3903e-01,  1.2617e-01,  1.5775e-01,  3.6257e-01, -2.6987e-01,\n",
       "         -1.0846e-01, -7.5441e-05, -6.7952e-02,  1.5841e-01, -1.6130e-01,\n",
       "         -2.5190e-01, -1.1635e-01,  2.6372e-01, -2.7255e-01,  1.5280e-01,\n",
       "          6.3483e-02,  1.3698e-01,  4.1025e-01,  2.1298e-01,  2.6332e-01,\n",
       "          7.0660e-02,  3.2315e-01,  1.9084e-01,  2.8368e-01, -2.7102e-01,\n",
       "          8.9537e-02,  2.0829e-01,  2.9579e-03, -1.6517e-01, -8.0759e-02,\n",
       "         -3.2568e-01,  1.0583e-01, -9.1002e-02,  5.6423e-01, -8.1700e-02,\n",
       "         -3.3222e-01, -3.1295e-01, -1.7700e-01,  1.4619e-01,  5.9623e-02,\n",
       "         -1.7463e-01,  2.0326e-01,  3.6428e-01,  3.0224e-02, -8.1831e-02,\n",
       "         -1.9133e-01, -4.2122e-01, -2.5760e-01,  3.3164e-02, -2.3620e-01,\n",
       "          3.7438e-01,  2.0098e-01, -2.1593e-01,  1.7424e-01,  7.0683e-03,\n",
       "          1.5084e-01,  4.3937e-01, -2.9243e-01,  1.9498e-01, -1.9167e-02,\n",
       "         -1.5924e-01, -6.0810e-01, -7.4131e-02, -9.5603e-02, -4.2661e-01,\n",
       "         -1.3907e-01,  1.0946e-02, -2.6400e-01,  5.6868e-02, -3.9135e-01,\n",
       "         -2.8152e-01,  1.9548e-01,  1.4492e-01, -1.1919e-01,  3.3419e-01,\n",
       "          5.2779e-02, -2.3525e-01, -1.9913e-01,  8.6434e-02,  3.0974e-02,\n",
       "          8.6939e-01, -1.2969e-01,  2.0370e-01, -1.9275e-01, -7.1325e-02,\n",
       "         -4.8060e-01,  9.9998e-01,  1.0734e-01, -6.8266e-02,  3.7017e-02,\n",
       "          9.5685e-02, -4.5283e-01,  1.7256e-01,  1.8617e-01,  2.1880e-01,\n",
       "          1.5577e-02, -7.1837e-02, -6.6301e-02, -3.9012e-01, -5.9940e-01,\n",
       "         -2.0116e-01, -2.1914e-01,  9.4719e-02, -3.5476e-02, -1.7849e-01,\n",
       "          1.8875e-01,  3.8375e-01, -5.5143e-02, -7.6702e-02, -1.0361e-01,\n",
       "          6.9491e-02,  1.0216e-02, -3.9416e-01,  9.9996e-01,  4.6227e-01,\n",
       "          9.0226e-02, -2.4190e-01,  8.7191e-02, -3.3330e-01, -2.1596e-01,\n",
       "         -1.7824e-01, -2.4695e-01, -4.6473e-01,  1.1479e-01,  2.0924e-01,\n",
       "          9.9151e-02, -1.5098e-01, -2.8622e-01, -1.7519e-01,  2.7355e-01,\n",
       "         -4.5380e-01, -9.1490e-02,  2.8317e-01,  2.9816e-01,  2.1182e-01,\n",
       "         -2.7589e-02,  2.8617e-01,  1.1243e-01, -1.6245e-01,  1.6081e-01,\n",
       "          2.9714e-01,  2.2641e-01,  4.2341e-02, -1.3905e-01,  1.4080e-01,\n",
       "          2.1347e-01, -4.4373e-02, -2.9004e-01, -9.1250e-02,  1.4685e-02,\n",
       "         -3.5326e-01, -9.5629e-02, -1.4129e-01, -1.0728e-01,  1.9104e-01,\n",
       "          2.2243e-02,  1.7879e-01, -2.3712e-01,  2.0832e-01,  4.0498e-01,\n",
       "          7.1750e-02, -4.2419e-01,  1.8542e-01,  3.2278e-01,  2.9223e-01,\n",
       "          4.4566e-02,  1.4173e-01,  2.1101e-01,  1.3969e-01, -1.1177e-01,\n",
       "         -3.1422e-01,  5.9157e-03,  7.9288e-02,  3.7278e-01, -8.1599e-02,\n",
       "         -4.7047e-01, -2.4473e-01,  5.7483e-01,  3.1722e-01, -2.2883e-01,\n",
       "         -2.5615e-02,  1.9473e-01, -4.4131e-02,  3.0968e-02,  1.6898e-01,\n",
       "         -3.2233e-02,  7.2389e-02, -3.2856e-01, -8.6676e-02, -6.6801e-02,\n",
       "          3.0453e-01,  1.5804e-01,  2.8967e-01,  1.0400e-01, -1.6214e-01,\n",
       "         -3.1393e-02, -1.3123e-01,  2.9179e-02,  2.7962e-01,  5.4562e-02,\n",
       "          5.8025e-01, -1.3286e-01,  2.1131e-01, -3.4381e-01, -2.1545e-01,\n",
       "          1.9066e-01, -1.5897e-01,  3.4125e-01,  7.8062e-01,  1.1484e-01,\n",
       "         -1.8754e-01,  5.7572e-02,  1.2480e-01,  1.5473e-01, -4.0365e-02,\n",
       "          5.1981e-03, -4.4120e-01,  4.0918e-01, -1.1587e-02,  8.9880e-02,\n",
       "         -9.9996e-01,  2.2643e-01,  1.1880e-01,  3.5637e-01,  7.0346e-02,\n",
       "          1.4445e-01,  1.5881e-01,  2.6125e-01,  6.7243e-01, -8.8318e-02,\n",
       "         -2.8093e-01, -1.9004e-01, -1.8290e-01, -3.0693e-01, -9.8876e-02,\n",
       "         -1.2646e-01, -2.0136e-01, -1.3297e-01,  3.3709e-02, -1.0722e-01,\n",
       "          2.6995e-01,  3.8542e-01, -9.3252e-01,  6.6175e-01,  3.0971e-01,\n",
       "         -1.5193e-01, -3.1967e-02,  2.4673e-01, -9.9997e-01,  2.0890e-01,\n",
       "         -1.6537e-01, -8.9530e-02,  1.2121e-01, -3.3900e-01, -2.7418e-01,\n",
       "          3.5292e-03,  3.6131e-01,  1.0605e-01,  2.3016e-01,  1.8032e-01,\n",
       "          3.8285e-01, -4.6646e-02,  1.0144e-01,  6.2134e-02, -1.7952e-01,\n",
       "          4.3474e-01,  1.0501e-02,  2.3656e-01,  3.1959e-01, -2.2539e-01,\n",
       "          1.1142e-01, -1.5296e-01,  3.2586e-01,  1.4391e-01,  8.6877e-02,\n",
       "          1.2131e-01, -1.5813e-01,  2.6550e-01, -5.8050e-01,  5.2000e-02,\n",
       "         -1.0987e-01, -4.3550e-02, -5.4122e-02, -3.0066e-02, -1.2098e-01,\n",
       "         -3.1707e-01,  4.7831e-02, -8.2619e-02,  9.9997e-01,  1.5200e-01,\n",
       "         -1.2371e-01, -1.3540e-01,  4.2200e-01,  3.2967e-01, -1.3757e-01,\n",
       "         -2.2947e-01,  5.3190e-02,  3.6353e-01,  2.2290e-01,  3.1847e-01,\n",
       "          7.7695e-02, -8.1345e-02,  1.6281e-01, -1.5153e-01,  1.5226e-01,\n",
       "          1.0482e-01, -3.3090e-01,  1.0627e-01, -1.2174e-01, -3.2549e-01,\n",
       "          1.8980e-01, -1.0929e-01, -1.0585e-01, -5.7544e-01,  1.9589e-01,\n",
       "          2.0691e-01,  4.4749e-03,  1.6830e-01,  2.0441e-01, -1.9342e-01,\n",
       "          4.0592e-01,  1.6316e-01, -2.9291e-01, -2.7323e-01, -1.9960e-01,\n",
       "         -1.3274e-01,  2.0586e-03, -2.9670e-01, -3.1427e-01,  7.1267e-02,\n",
       "         -4.3984e-01,  1.7029e-01,  4.8101e-02, -3.9651e-02, -2.4693e-01,\n",
       "          2.7535e-01, -9.9998e-01, -2.4189e-01,  1.8905e-02, -2.7178e-01,\n",
       "          2.2369e-01, -1.5951e-01, -2.3595e-01,  2.0465e-01,  1.2326e-01,\n",
       "          3.7682e-02, -1.5389e-01, -1.5726e-01, -7.3485e-02, -7.9993e-02,\n",
       "          7.1012e-02,  6.5539e-01,  2.3104e-01,  6.8948e-02, -1.1218e-01,\n",
       "          4.8061e-02, -3.3215e-01, -4.8409e-02,  2.9354e-01,  1.4764e-01,\n",
       "         -2.2776e-01,  1.1909e-01,  4.0026e-02,  5.0594e-02,  1.0616e-01,\n",
       "          3.3183e-01, -8.4301e-02, -1.2076e-01,  3.5285e-01, -2.6304e-03,\n",
       "         -6.5603e-02, -1.1948e-01,  3.1938e-01, -3.5743e-01,  2.0680e-01,\n",
       "          8.0217e-02,  8.4074e-02,  3.0980e-02,  1.5173e-01, -1.9611e-01,\n",
       "          1.0327e-01, -1.4627e-01, -1.6179e-01, -3.3709e-01, -1.9404e-01,\n",
       "          6.1461e-03,  9.9997e-01,  2.9481e-01,  2.6252e-01, -2.6023e-01,\n",
       "          3.2706e-02,  1.4408e-01, -2.3605e-01,  2.2329e-01,  3.1396e-01,\n",
       "          2.7954e-01, -3.1147e-01,  4.1527e-02,  3.0544e-02,  3.3692e-01,\n",
       "          1.7132e-01,  3.5057e-02,  2.1357e-01, -2.3351e-01,  3.8485e-01,\n",
       "         -2.0459e-01, -3.2541e-01, -9.4345e-01,  1.9204e-01,  2.4353e-01,\n",
       "         -2.9203e-01, -3.5258e-01,  1.5454e-01, -1.7139e-01,  5.6609e-02,\n",
       "          8.8640e-03,  2.1585e-01,  1.2680e-01,  5.9238e-02,  3.5345e-01,\n",
       "         -2.4877e-01,  9.9997e-01,  6.8203e-02,  2.1601e-01,  2.4479e-01,\n",
       "          1.3064e-01, -4.8283e-02, -1.2029e-01,  4.0287e-02,  2.7597e-01,\n",
       "          5.8327e-03, -1.0939e-01, -7.8818e-01,  2.2078e-01,  2.5583e-02,\n",
       "          4.8694e-01, -2.4151e-01,  1.1074e-01, -4.6020e-01,  3.6728e-01,\n",
       "          1.6578e-02, -1.1854e-01, -3.2694e-01,  2.1967e-01, -3.2946e-01,\n",
       "          3.2286e-01, -2.1522e-01,  1.1058e-01, -2.1338e-01,  1.1442e-01,\n",
       "         -1.0182e-01,  2.0868e-01, -1.1850e-01,  3.4316e-02, -1.1117e-01,\n",
       "         -1.2921e-01, -2.1429e-01,  4.1157e-02, -2.2392e-01,  9.9997e-01,\n",
       "         -8.2463e-02,  9.9145e-02, -2.6229e-02,  1.4253e-01, -1.6934e-01,\n",
       "          3.0254e-01,  3.9592e-01, -2.0287e-01,  1.3929e-01,  1.5085e-01,\n",
       "         -3.7693e-01,  1.9295e-01, -7.8766e-02, -4.4108e-01, -1.2649e-01,\n",
       "          8.0923e-01,  4.3545e-02,  2.4159e-01,  1.9361e-01,  2.2820e-02,\n",
       "         -4.3180e-02, -3.1148e-02,  6.3110e-02,  7.0840e-01,  1.8451e-01,\n",
       "          2.5407e-01,  2.3663e-01,  1.2746e-01, -2.4545e-01, -1.7031e-01,\n",
       "          9.9997e-01,  9.9997e-01,  9.4432e-02,  1.3001e-01, -4.4266e-01,\n",
       "         -2.5708e-01, -8.3940e-02,  2.6343e-01,  5.6422e-02,  1.6896e-01,\n",
       "         -1.9203e-01, -1.3542e-02, -2.5332e-01, -2.2475e-01, -1.9685e-02,\n",
       "         -5.4280e-02, -2.4453e-01,  3.7486e-02, -1.7058e-01,  2.5376e-01,\n",
       "          1.9511e-01,  2.1362e-02,  3.6446e-01,  1.7003e-01,  1.5943e-01,\n",
       "         -1.5037e-01, -2.2144e-01,  2.2529e-01, -2.2227e-01,  6.3472e-02,\n",
       "         -2.1987e-01, -1.9261e-02, -9.9996e-01, -1.2640e-01, -2.5267e-01,\n",
       "         -2.8908e-01,  3.4311e-01,  1.5955e-01, -2.5967e-02, -2.1549e-01,\n",
       "         -5.1205e-02, -2.0287e-01,  1.6722e-01,  1.0921e-01,  2.4528e-02,\n",
       "         -1.6466e-01, -4.8302e-01,  4.4354e-01, -3.5571e-01,  2.2543e-01,\n",
       "         -2.3129e-01, -2.5574e-01, -4.9288e-01, -1.5142e-01, -1.7531e-01,\n",
       "          2.9562e-01, -9.8100e-02, -2.2247e-01,  2.3475e-01,  2.3932e-01,\n",
       "          1.7163e-01, -2.3469e-01,  2.9631e-01, -1.6203e-01,  7.4101e-02,\n",
       "          1.2960e-01,  4.8654e-04, -5.4095e-03, -9.4069e-02, -3.9289e-01,\n",
       "         -1.3687e-01, -8.8686e-02, -2.3583e-01,  1.6911e-01, -9.5120e-02,\n",
       "          1.2670e-01, -2.4738e-02,  3.0978e-01, -2.5483e-01, -4.1406e-03,\n",
       "          2.7042e-01,  3.8121e-01, -3.0442e-01,  2.8713e-01,  2.0503e-01,\n",
       "         -8.7171e-03,  3.6682e-01,  7.2140e-02, -1.1291e-01, -5.8694e-03,\n",
       "          9.9998e-01,  2.1273e-01,  2.4270e-01,  7.0467e-02, -1.8542e-02,\n",
       "          7.3188e-02,  2.3693e-01,  3.6441e-01, -1.4031e-01,  4.5184e-01,\n",
       "         -8.7513e-02,  2.1044e-01,  1.3674e-01,  2.3487e-01,  1.9225e-02,\n",
       "          7.6119e-02,  1.9802e-01,  4.8715e-01,  1.6304e-02,  1.6427e-01,\n",
       "          2.3698e-01,  1.7321e-01,  1.2925e-01,  1.7654e-01,  2.3436e-01,\n",
       "          2.0578e-01,  2.2873e-01, -1.1836e-01,  7.3751e-02, -1.5103e-01,\n",
       "         -1.9061e-02, -9.3468e-02, -1.2649e-01, -1.5930e-01,  8.3296e-02,\n",
       "         -1.5703e-01, -1.9276e-01, -1.2358e-01,  3.9718e-02, -1.5057e-01,\n",
       "          2.3783e-01, -1.7716e-01, -2.2540e-01,  2.5455e-01, -3.1145e-01,\n",
       "          2.1589e-01,  6.5972e-03,  1.8848e-01, -6.3116e-01,  1.4339e-01,\n",
       "         -1.1546e-01, -4.0903e-01, -1.4314e-01, -3.0826e-01,  1.7458e-01,\n",
       "          8.4285e-02,  9.3997e-02,  2.3579e-01, -1.5952e-01,  3.4430e-01,\n",
       "         -1.0035e-01, -1.4982e-01,  1.4246e-01, -9.9997e-01,  5.5006e-02,\n",
       "          1.1266e-01, -6.0734e-02, -1.6733e-02,  9.6640e-02,  1.4015e-01,\n",
       "          1.7706e-01, -2.9307e-02, -9.2526e-02, -5.2424e-02,  1.9207e-01,\n",
       "         -1.9533e-01, -7.6051e-03,  2.0339e-01, -2.4974e-01, -2.9400e-01,\n",
       "         -1.0173e-01, -6.6200e-02,  5.0014e-03,  1.1729e-01, -2.2430e-01,\n",
       "          1.0441e-01, -1.9317e-01,  1.5764e-01, -7.4989e-02,  2.9763e-01,\n",
       "         -1.5026e-01, -1.9444e-01,  1.5448e-01, -2.3327e-01, -3.1677e-01,\n",
       "         -2.5415e-02,  1.2538e-01,  1.0820e-01, -1.4640e-01,  1.3685e-01,\n",
       "         -1.7855e-01,  3.4729e-01, -1.8365e-01,  2.0332e-01, -2.5513e-01,\n",
       "          3.2444e-02, -6.1313e-01, -2.0531e-01, -2.8170e-01, -3.1272e-01,\n",
       "          2.6187e-01,  2.6391e-01, -5.5602e-02,  5.6974e-02, -9.8010e-03,\n",
       "          3.3680e-02, -8.9444e-02, -6.1375e-02,  2.4628e-01, -2.2639e-01,\n",
       "          1.1438e-01, -1.6317e-01,  9.3077e-02, -2.3987e-01,  4.8477e-03,\n",
       "         -9.1833e-01, -8.3130e-02,  1.7032e-01,  3.4631e-01,  2.7890e-01,\n",
       "         -1.7360e-01,  6.5522e-03, -2.6620e-01,  1.1666e-01,  5.1893e-02,\n",
       "          6.3156e-02,  2.0025e-01,  7.1333e-02,  1.6172e-01, -1.6218e-01,\n",
       "          2.0703e-01,  4.7669e-01, -2.0949e-01,  6.0353e-02,  1.0853e-01,\n",
       "          2.0369e-01,  5.5116e-01,  2.4429e-01,  2.3996e-01,  9.1928e-02,\n",
       "         -3.5868e-01,  1.9777e-01,  2.0208e-01]], grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bert-base-multilingual-cased\n",
    "# Run time: 19m\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "\n",
    "get_avg_res(tokenizer,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9158712517996491\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CausalLMOutputWithCrossAttentions(loss=None, logits=tensor([[[ -7.6904,  -7.6700, -10.2259,  ...,  -4.4806,  -6.2410,  -2.9573],\n",
       "         [-16.1794, -16.4799, -17.6944,  ...,  -5.7863,  -9.9725, -10.2662],\n",
       "         [-27.4192, -27.5182, -25.3408,  ...,  -9.7856, -10.2534, -14.2252]]],\n",
       "       grad_fn=<UnsafeViewBackward0>), past_key_values=((tensor([[[[ 1.4389, -0.9259,  3.1674,  ..., -0.1491,  0.7358,  0.4069],\n",
       "          [ 2.1965,  0.1825,  2.4464,  ..., -1.2019,  2.2887,  1.0410],\n",
       "          [ 2.1519, -0.5390,  2.3420,  ..., -1.7927,  4.5300,  1.1086]],\n",
       "\n",
       "         [[-1.1474,  0.0534, -0.8365,  ..., -0.0897, -0.9978,  0.8247],\n",
       "          [ 0.0865,  0.8130,  0.7836,  ..., -0.6327, -0.0927,  2.2687],\n",
       "          [-1.3778, -0.4761, -1.7145,  ...,  0.4187, -0.2740,  2.0218]],\n",
       "\n",
       "         [[ 1.0041, -1.1440,  0.6039,  ..., -0.1498,  0.7908,  0.7858],\n",
       "          [ 0.2596, -0.2843,  0.5057,  ...,  0.3007,  0.4995,  0.3799],\n",
       "          [ 1.0470, -0.5683, -0.1906,  ...,  0.2936, -0.6122,  1.0293]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.3481, -1.1263,  0.0169,  ...,  0.8758,  0.0102,  1.1217],\n",
       "          [ 0.1321,  0.8777, -0.9890,  ..., -0.1169, -0.9111,  2.2177],\n",
       "          [-0.1360, -0.7906,  0.2302,  ..., -1.0067, -1.1675,  0.9896]],\n",
       "\n",
       "         [[-1.4403, -2.0948, -0.4073,  ...,  0.7308,  0.8227,  2.0536],\n",
       "          [-0.9501, -3.3383, -1.2906,  ..., -1.5535, -1.0963,  4.2450],\n",
       "          [-0.7806, -1.2748, -2.0330,  ...,  0.5439, -0.5596,  0.7157]],\n",
       "\n",
       "         [[-0.9335, -0.5198, -0.3600,  ...,  2.2158, -0.8686, -0.3618],\n",
       "          [-1.8280, -1.9752,  0.1880,  ...,  0.1175,  0.9936,  0.4965],\n",
       "          [-1.0761,  1.1975, -0.7649,  ...,  0.5619, -0.7999, -1.4238]]]],\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[-0.3847,  0.0361,  1.5380,  ...,  1.2042, -0.6043, -0.1632],\n",
       "          [ 0.2219,  0.1451, -1.0946,  ...,  0.6353, -0.7125,  0.3543],\n",
       "          [-0.2406, -0.0944,  0.5716,  ...,  0.6819, -0.6052, -0.9237]],\n",
       "\n",
       "         [[ 0.1290,  0.6067, -0.3906,  ..., -0.5122, -1.8282,  0.5831],\n",
       "          [ 0.1377,  0.7342,  0.3602,  ...,  0.2353,  1.3481,  0.3576],\n",
       "          [ 0.5194,  0.6869,  0.4612,  ...,  0.0412,  0.2653, -1.6963]],\n",
       "\n",
       "         [[ 0.5820,  0.6870, -0.5023,  ...,  0.8071,  1.3252,  0.4686],\n",
       "          [ 0.4658,  1.1051, -0.6255,  ...,  0.4531,  1.3857,  0.9884],\n",
       "          [-0.5019,  0.2441, -0.0292,  ...,  0.9949,  0.7353,  0.2242]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0980, -1.0473,  0.7937,  ...,  0.7939, -0.1286, -1.0432],\n",
       "          [-0.1226,  0.0671, -0.0783,  ..., -0.0201, -0.6135,  0.4658],\n",
       "          [ 0.0340,  0.4670, -0.2142,  ..., -0.1441,  0.2997, -0.2740]],\n",
       "\n",
       "         [[-0.9660, -1.0267, -0.0979,  ...,  0.9098, -0.4099,  0.4510],\n",
       "          [-0.1700, -0.5315,  0.3870,  ..., -0.8472, -0.2051,  0.8376],\n",
       "          [-0.7312, -0.6976, -0.5520,  ..., -0.5664,  0.4906,  1.0264]],\n",
       "\n",
       "         [[ 0.2282, -0.2516,  0.2754,  ..., -0.6725, -0.6418,  0.9359],\n",
       "          [ 0.6297, -0.0191, -0.4682,  ..., -0.0809,  0.6665, -0.3224],\n",
       "          [-1.1781,  0.2567, -0.7840,  ..., -0.9873,  0.0154,  0.9465]]]],\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[ 6.4184e-01, -7.8239e-01,  1.4873e+00,  ...,  9.0654e-01,\n",
       "           -1.5208e-01,  1.6653e+00],\n",
       "          [ 1.0641e+00, -3.1238e-01,  8.8780e-01,  ...,  2.0023e+00,\n",
       "            8.7335e-01,  9.5116e-01],\n",
       "          [ 3.0089e-02, -4.5564e-01,  8.3630e-02,  ...,  1.3663e+00,\n",
       "           -5.1471e-01,  1.5187e+00]],\n",
       "\n",
       "         [[ 6.0176e-01, -3.2693e-01, -3.8814e-01,  ..., -1.1017e-01,\n",
       "           -1.1140e+00, -5.3824e-01],\n",
       "          [ 1.0019e-01,  2.4403e-01, -1.0954e+00,  ...,  3.2725e-01,\n",
       "            2.2066e-01,  5.4258e-01],\n",
       "          [ 7.6049e-01, -8.4722e-01, -2.0633e+00,  ...,  1.3355e+00,\n",
       "           -3.3496e-01,  1.5403e+00]],\n",
       "\n",
       "         [[-1.4639e+00,  6.9933e-01, -3.7205e-02,  ...,  1.4477e-01,\n",
       "           -9.6428e-01, -2.5574e-01],\n",
       "          [-1.1847e+00,  7.8550e-01,  5.2439e-01,  ..., -2.5283e-01,\n",
       "           -2.6749e-01,  7.3235e-02],\n",
       "          [-1.2415e+00,  1.1862e+00,  4.3271e-01,  ...,  1.0958e-01,\n",
       "           -1.0840e+00,  2.4953e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-6.4567e-01, -4.1569e+00,  1.6930e-02,  ..., -2.2033e+00,\n",
       "           -3.6246e+00,  2.1195e+00],\n",
       "          [ 6.0013e-01,  4.9824e-01, -1.4134e-01,  ...,  1.0464e-02,\n",
       "           -4.0082e+00, -1.7606e+00],\n",
       "          [ 7.0619e-01, -7.6458e-02, -7.3912e-01,  ...,  1.8697e+00,\n",
       "           -1.7521e+00,  2.1698e+00]],\n",
       "\n",
       "         [[ 8.2537e-01,  1.0110e+00, -4.9825e-01,  ...,  7.1767e-01,\n",
       "           -7.5008e-01, -6.8449e-01],\n",
       "          [-8.8787e-01, -2.4140e-03, -6.2843e-01,  ..., -1.8289e-01,\n",
       "           -4.8903e-01, -5.6148e-01],\n",
       "          [-4.9828e-01, -3.3662e-01, -8.5044e-01,  ..., -2.4403e-01,\n",
       "           -4.1928e-01,  5.4902e-01]],\n",
       "\n",
       "         [[ 3.9750e-01, -5.8534e-01, -4.0455e-01,  ...,  1.9951e-01,\n",
       "            1.2389e+00, -1.3055e+00],\n",
       "          [-3.1303e-01, -1.0661e+00, -6.1580e-01,  ...,  5.5239e-01,\n",
       "            8.8184e-01,  4.8741e-02],\n",
       "          [ 1.6812e-01, -1.6146e+00, -3.8173e-01,  ...,  1.1081e+00,\n",
       "            1.2949e-01, -1.4049e-01]]]], grad_fn=<PermuteBackward0>), tensor([[[[ 0.3132,  0.3496,  0.1727,  ...,  0.2722, -0.5270, -0.0541],\n",
       "          [-0.4613,  0.2319,  0.3401,  ...,  0.8155,  1.1096, -0.8244],\n",
       "          [-0.4098,  0.6995, -0.2903,  ...,  0.9437,  0.2639, -0.4502]],\n",
       "\n",
       "         [[ 0.9836, -0.0784, -0.2844,  ..., -0.2582,  0.4167, -0.2624],\n",
       "          [ 0.8230, -0.3972,  0.2530,  ..., -0.1726, -0.1728,  0.9165],\n",
       "          [ 0.0515,  0.1860,  0.4405,  ..., -0.1931,  0.1375,  0.3715]],\n",
       "\n",
       "         [[ 0.2452,  0.0902, -0.2913,  ...,  0.7041,  0.7848,  0.4553],\n",
       "          [ 0.1185,  0.1378, -0.6114,  ..., -0.2542,  0.9582,  0.0560],\n",
       "          [ 0.2246, -0.3961, -0.4523,  ..., -0.2641,  0.5294,  0.2426]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.6484, -0.0331, -0.1436,  ...,  0.3715, -0.7075, -0.2669],\n",
       "          [-0.6679, -0.1374,  0.8334,  ...,  0.6135, -0.1251,  0.6400],\n",
       "          [-0.2490, -0.0539,  0.0781,  ...,  0.0532,  0.2717,  0.0850]],\n",
       "\n",
       "         [[ 0.5304,  0.2616, -0.2939,  ..., -0.3936,  0.0664,  0.4827],\n",
       "          [-0.2750, -0.1120, -0.3571,  ..., -0.5028, -0.0645, -0.4100],\n",
       "          [ 0.0870,  0.1129,  0.1508,  ..., -0.1838,  0.3846, -0.1977]],\n",
       "\n",
       "         [[ 0.2602, -0.2582, -0.4208,  ...,  0.2445, -0.0981,  0.4146],\n",
       "          [-0.7727,  0.5096,  0.6737,  ..., -0.2083, -0.1618, -0.3318],\n",
       "          [-0.3821,  0.2087,  0.3366,  ...,  0.2565,  0.1942,  0.2493]]]],\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[-0.1010, -1.2106, -2.9089,  ...,  2.5486,  4.3984,  0.3432],\n",
       "          [-0.4765, -1.9775, -2.6914,  ...,  2.5334,  5.5021,  2.8971],\n",
       "          [ 1.3575, -0.4793, -5.8828,  ...,  5.8751,  4.9532,  2.1844]],\n",
       "\n",
       "         [[-1.2658,  2.2509,  2.7505,  ..., -1.1996, -0.7285,  2.5115],\n",
       "          [-1.4872,  2.6418,  5.3012,  ..., -0.6303, -2.1334,  2.8604],\n",
       "          [-0.6916,  1.7433,  4.8009,  ..., -1.7876, -1.7221,  3.5362]],\n",
       "\n",
       "         [[ 2.0207,  1.1298,  1.2591,  ...,  1.1174, -0.3348, -3.4247],\n",
       "          [ 1.7824,  2.4682,  0.4050,  ...,  2.0032, -0.2170, -5.3065],\n",
       "          [ 0.7815,  0.3649, -0.0492,  ...,  1.9055,  0.7004, -4.8609]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.3251,  0.2985,  0.2925,  ..., -0.8530,  0.3857, -1.1800],\n",
       "          [ 0.1611,  0.1528, -0.0862,  ...,  0.2163,  0.3631, -0.2894],\n",
       "          [ 0.5987,  0.3224,  0.1630,  ..., -0.6579, -0.1491, -0.9443]],\n",
       "\n",
       "         [[ 0.7882, -4.3196, -2.3260,  ..., -0.7088, -1.6125,  2.7913],\n",
       "          [ 1.6617, -4.5316, -3.9668,  ..., -0.2301, -2.7064,  2.7527],\n",
       "          [ 1.0142, -5.9711, -3.0573,  ...,  0.5501, -2.4761,  2.0174]],\n",
       "\n",
       "         [[-1.7094,  0.1786,  1.1292,  ...,  0.9158, -1.5231, -2.7755],\n",
       "          [-2.1204, -1.7730,  1.1226,  ...,  0.9584, -2.3964, -4.0816],\n",
       "          [-1.7981, -0.8484,  0.1343,  ...,  1.1964, -3.3179, -3.7939]]]],\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[-2.0552e-02, -3.3684e-03,  5.1393e-02,  ...,  3.4725e-01,\n",
       "            1.7048e-01,  6.8718e-02],\n",
       "          [ 3.8521e-04,  9.5048e-01,  1.9784e-01,  ..., -4.5120e-01,\n",
       "           -2.5015e-03, -1.7705e-01],\n",
       "          [ 1.0049e-01,  2.6187e-01,  5.2813e-01,  ...,  1.4611e-01,\n",
       "           -4.9621e-01,  2.3009e-01]],\n",
       "\n",
       "         [[-1.5589e-01, -3.3925e-01, -1.3154e-01,  ..., -2.5077e-02,\n",
       "            6.1321e-02, -2.6774e-01],\n",
       "          [ 4.6890e-02, -3.0136e-01, -8.9475e-01,  ..., -4.8868e-01,\n",
       "            1.3148e-01, -1.9095e-01],\n",
       "          [-4.0711e-01,  4.6076e-01, -6.0287e-01,  ...,  1.4465e-01,\n",
       "           -8.0491e-01, -4.5800e-01]],\n",
       "\n",
       "         [[ 1.8383e-01,  1.7397e-01, -1.9982e-01,  ...,  3.1763e-05,\n",
       "           -1.4567e-01, -2.4972e-01],\n",
       "          [ 7.3443e-01,  4.9046e-01, -2.4481e-01,  ...,  4.9419e-01,\n",
       "            2.3217e-01, -3.2662e-01],\n",
       "          [ 7.5813e-01, -3.2977e-01,  5.2110e-01,  ...,  7.4211e-03,\n",
       "           -6.9949e-01, -3.5615e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.0972e-01,  1.8398e-01, -2.9527e-01,  ...,  1.1593e-01,\n",
       "           -4.9593e-02,  1.1147e-01],\n",
       "          [ 4.5043e-01, -4.6948e-01,  1.5919e-01,  ..., -1.0675e+00,\n",
       "           -5.6597e-01,  8.1631e-01],\n",
       "          [ 2.9428e-01, -3.2744e-02,  9.5986e-02,  ..., -7.5229e-01,\n",
       "           -1.6455e-01,  1.0412e+00]],\n",
       "\n",
       "         [[ 2.4066e-01,  1.5380e-01,  2.2352e-02,  ..., -2.8346e-02,\n",
       "           -2.4863e-01,  1.3138e-01],\n",
       "          [ 3.5015e-01,  2.1843e-01, -8.3470e-02,  ..., -2.2694e-01,\n",
       "            5.2348e-01,  1.0503e+00],\n",
       "          [ 4.2535e-01, -8.0405e-01,  3.2628e-01,  ..., -2.2436e-01,\n",
       "            2.3436e-01, -4.0875e-01]],\n",
       "\n",
       "         [[ 6.1234e-01,  5.0567e-01, -1.9563e-01,  ..., -4.5906e-01,\n",
       "           -6.4616e-01,  2.5307e-01],\n",
       "          [ 6.1330e-02,  5.5673e-01,  4.5005e-02,  ...,  4.1833e-01,\n",
       "           -1.0426e+00, -7.5954e-01],\n",
       "          [-5.2762e-02,  7.3817e-01, -6.6414e-01,  ..., -3.7020e-01,\n",
       "            1.0445e-01,  1.3434e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[ 5.5941,  2.4748, -2.4736,  ...,  5.7737,  4.1723, -4.0396],\n",
       "          [ 6.0999,  2.9141, -3.6322,  ...,  5.2711,  2.8695, -5.6867],\n",
       "          [ 6.1677,  2.1597, -3.0251,  ...,  5.5087,  2.6549, -5.7321]],\n",
       "\n",
       "         [[ 6.5284,  9.0013, -3.1233,  ..., -0.0920, -2.1038,  4.3437],\n",
       "          [ 8.0073,  8.6227, -4.2994,  ...,  0.3701, -2.2631,  3.4174],\n",
       "          [ 8.0311, 10.1859, -2.8509,  ..., -0.1912, -1.8397,  2.7183]],\n",
       "\n",
       "         [[ 2.3041, -0.4271, -1.2459,  ...,  3.8545,  1.9430,  2.4639],\n",
       "          [ 1.9446,  1.0401, -1.3318,  ...,  4.0270,  2.0032,  2.7905],\n",
       "          [ 3.4338,  0.5289, -0.9823,  ...,  4.0009,  1.5733,  2.8250]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.7173,  5.1115, -2.3778,  ...,  0.9158, -1.8267,  2.6552],\n",
       "          [ 3.5509,  6.6904, -1.6397,  ...,  0.7214, -4.5562,  1.1347],\n",
       "          [ 2.3883,  6.8430, -2.8721,  ...,  1.1666, -2.1765,  2.7291]],\n",
       "\n",
       "         [[ 0.3823, -0.1391,  1.9721,  ..., -0.8614,  1.1728,  0.2383],\n",
       "          [ 0.8797, -0.2780,  2.4572,  ...,  0.6411,  0.9224, -1.0434],\n",
       "          [ 1.3596, -0.2554,  3.6601,  ...,  0.0463, -0.0211,  1.0589]],\n",
       "\n",
       "         [[ 7.7081, -4.8135, -6.2203,  ...,  3.8965, -1.1894, -0.7451],\n",
       "          [ 7.8251, -4.0961, -7.7221,  ...,  5.1766, -2.2838, -1.5667],\n",
       "          [ 9.0174, -3.2521, -5.4589,  ...,  6.3107, -3.6741, -3.8016]]]],\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[ 0.0047, -0.2502,  0.3121,  ...,  0.1253,  0.0028, -0.3735],\n",
       "          [ 0.4856,  0.1250,  0.8318,  ...,  0.3867, -0.0206,  0.9246],\n",
       "          [ 0.3268, -1.2113,  0.2004,  ..., -0.3888, -0.1468,  0.3949]],\n",
       "\n",
       "         [[-0.0217,  0.1937, -0.3632,  ...,  0.1248,  0.4788,  0.3543],\n",
       "          [-1.1218,  0.3455,  0.9022,  ...,  0.2697,  0.4785,  0.7583],\n",
       "          [-0.6269,  1.1014,  0.1799,  ...,  0.2627,  0.6407, -0.7103]],\n",
       "\n",
       "         [[ 0.0026, -0.6409,  0.0365,  ..., -0.2238, -0.2533, -0.4154],\n",
       "          [-0.1948, -0.1267, -0.4890,  ..., -1.9092,  0.1413, -0.3493],\n",
       "          [-0.7809,  0.3713, -0.0589,  ..., -0.6111, -0.5900, -0.1273]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0257, -0.1229, -0.2454,  ...,  0.0592,  0.1004, -0.3407],\n",
       "          [ 0.0665,  1.0741, -0.7520,  ..., -0.1237,  0.6579,  0.5752],\n",
       "          [-0.0372,  0.6195,  0.6066,  ...,  0.1095, -0.3985,  0.4934]],\n",
       "\n",
       "         [[-0.1234, -0.5579,  0.1878,  ..., -0.0132,  0.2760,  0.4764],\n",
       "          [ 0.3462, -0.4626,  0.8368,  ...,  0.3231,  1.1916, -0.3301],\n",
       "          [-0.8318, -0.3520,  0.2721,  ..., -1.0123,  0.2188,  1.4625]],\n",
       "\n",
       "         [[ 0.0478, -0.1914, -0.3407,  ..., -0.1157, -0.5101, -0.0552],\n",
       "          [-0.8570, -0.6158,  0.5083,  ...,  0.3695,  0.3049, -0.3520],\n",
       "          [-0.3322, -0.2056, -0.3893,  ...,  0.3895,  0.5861, -0.4678]]]],\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[ 6.6270,  0.5325,  2.2697,  ...,  5.7674, -6.9499,  3.2694],\n",
       "          [ 6.5253,  0.1684,  1.9121,  ...,  6.3202, -8.2171,  4.3429],\n",
       "          [ 8.6372,  0.9058,  1.9151,  ...,  7.2161, -7.2610,  4.3354]],\n",
       "\n",
       "         [[ 3.2166, -2.4764, -0.4705,  ...,  0.0589, -0.4462, -2.2298],\n",
       "          [ 2.3970, -3.1202,  0.5589,  ...,  0.1647, -0.2212, -1.7525],\n",
       "          [ 3.1397, -4.4692, -0.1264,  ...,  1.3951, -0.1844, -1.8144]],\n",
       "\n",
       "         [[-0.6027,  0.6933,  8.1922,  ..., -4.0664,  0.6903,  2.1905],\n",
       "          [ 2.0787,  2.3542,  8.5431,  ..., -4.4400,  1.9088,  4.6337],\n",
       "          [ 0.3384,  0.5643,  8.4440,  ..., -4.3458,  1.4073,  3.7513]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.4794,  0.7648, -2.1644,  ..., -0.6821,  0.0515, -4.3614],\n",
       "          [-0.5181, -0.4612, -3.5612,  ..., -0.6471,  1.8209, -6.9838],\n",
       "          [-0.8159,  0.9499, -2.3291,  ..., -2.5145,  0.4637, -6.7776]],\n",
       "\n",
       "         [[ 3.2343,  0.3157, -4.9700,  ...,  5.0498,  1.6213, -6.8751],\n",
       "          [ 4.5308, -0.1824, -6.7270,  ...,  5.3130,  1.9809, -6.3485],\n",
       "          [ 5.0068,  0.2489, -6.4369,  ...,  5.7582,  1.5650, -6.4167]],\n",
       "\n",
       "         [[-0.7216,  3.5108,  1.7707,  ...,  3.2062,  0.1753, -0.1811],\n",
       "          [-0.5282,  2.8329,  0.0384,  ...,  3.9127,  0.8849,  1.0815],\n",
       "          [ 0.1978,  3.4506, -0.3896,  ...,  4.3236,  1.6851,  0.4195]]]],\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[-0.0916,  0.1185, -0.1123,  ...,  0.0728, -0.1306,  0.0896],\n",
       "          [-0.8375, -0.3106,  0.7003,  ...,  1.4363,  0.5255, -0.0050],\n",
       "          [ 0.3624,  0.6303,  0.1931,  ...,  1.2046, -0.2356,  0.7514]],\n",
       "\n",
       "         [[-0.2574,  0.1633,  0.1525,  ..., -0.2218, -0.2653,  0.1942],\n",
       "          [-1.3971,  0.3032,  0.6223,  ..., -0.1270,  0.2009, -0.7550],\n",
       "          [-0.7099,  0.3107, -0.1272,  ...,  0.9731, -0.2386, -1.4310]],\n",
       "\n",
       "         [[-0.4780,  0.0362, -0.2610,  ..., -0.0346, -0.0019,  0.4588],\n",
       "          [-0.2853, -0.4212,  0.1694,  ..., -1.4098, -0.3238,  0.4525],\n",
       "          [-0.4657, -0.3192,  0.3975,  ..., -0.1846, -1.0275, -0.3748]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.4190,  0.2382,  0.1234,  ..., -0.1894, -0.5477, -0.0794],\n",
       "          [-1.5445, -0.6963, -0.0572,  ..., -0.5735,  0.2258,  0.3940],\n",
       "          [-1.0573, -0.4841, -0.2767,  ..., -1.2454,  0.2614, -1.0801]],\n",
       "\n",
       "         [[-0.2469, -0.0030, -0.1309,  ..., -0.0961,  0.0906,  0.3452],\n",
       "          [-0.0523,  1.0264,  1.2005,  ...,  0.1640, -0.1031,  0.1617],\n",
       "          [ 0.5616,  1.3529,  0.6964,  ...,  0.5529,  0.0578,  0.2785]],\n",
       "\n",
       "         [[-0.5496,  0.1443, -0.5717,  ...,  0.2827,  0.2436,  0.2971],\n",
       "          [-1.1436,  0.8307, -0.5132,  ...,  0.4717,  1.0420, -0.0153],\n",
       "          [-0.6221,  0.8175, -0.8228,  ..., -1.4183,  0.0964, -0.2613]]]],\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[-1.5728,  3.2700,  4.5486,  ..., -6.3972,  4.6597, -4.6214],\n",
       "          [-0.5280,  4.1757,  7.0847,  ..., -6.5733,  5.1750, -4.0214],\n",
       "          [-0.9118,  2.5118,  9.1487,  ..., -7.0182,  6.0074, -4.0076]],\n",
       "\n",
       "         [[-4.0868,  2.2882,  4.7745,  ...,  2.6310,  0.7469, -6.6086],\n",
       "          [-3.9074,  1.5080,  4.1748,  ...,  1.4743,  1.6382, -6.5415],\n",
       "          [-5.0429,  3.0124,  3.3669,  ...,  1.1504,  0.8795, -6.7367]],\n",
       "\n",
       "         [[-5.2354, -3.4572, -4.1336,  ...,  0.3275,  0.7071,  2.3101],\n",
       "          [-5.4759, -3.8710, -4.1075,  ...,  0.0847,  1.7411,  3.2379],\n",
       "          [-4.8266, -3.8306, -2.1294,  ..., -1.5981,  1.2964,  3.7695]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.8615,  0.4614, -0.6952,  ..., -0.5778, -1.2402, -1.6903],\n",
       "          [-1.4107,  1.2858,  1.0070,  ...,  0.8973, -3.2323, -3.0965],\n",
       "          [-1.2552,  1.1767, -0.5701,  ...,  0.6169, -1.4318, -1.6089]],\n",
       "\n",
       "         [[ 1.3544,  0.1461,  3.0031,  ...,  1.7306,  1.0204,  2.2907],\n",
       "          [ 4.8974, -0.9491,  4.2145,  ...,  3.2430,  2.0067,  3.5752],\n",
       "          [ 3.7767, -1.4001,  5.9844,  ...,  1.1140,  1.8250,  2.7244]],\n",
       "\n",
       "         [[ 7.4187,  0.8888,  4.6540,  ...,  0.9044,  5.0434, -2.3239],\n",
       "          [ 5.6950,  1.4632,  3.8249,  ...,  1.1755,  6.2781, -3.0624],\n",
       "          [ 6.8113,  2.5495,  4.6087,  ...,  1.1173,  7.5378, -3.3858]]]],\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[ 3.0623e-01, -2.9633e-01,  1.4000e-01,  ...,  1.1836e-01,\n",
       "           -1.0634e-01,  2.3664e-01],\n",
       "          [ 6.6512e-01,  1.1884e-01,  3.6954e-01,  ...,  6.8558e-01,\n",
       "            4.5774e-01,  3.8226e-01],\n",
       "          [-1.8467e-01, -1.4789e+00,  4.7379e-01,  ...,  4.6188e-01,\n",
       "            5.5199e-01,  1.4965e+00]],\n",
       "\n",
       "         [[ 1.3800e-01,  7.3480e-02, -1.7203e-02,  ...,  5.4970e-02,\n",
       "            3.2905e-01,  3.1531e-01],\n",
       "          [-2.2468e-01,  5.3436e-02,  4.8486e-01,  ..., -1.5044e+00,\n",
       "           -3.8396e-02,  2.5252e-03],\n",
       "          [-9.9755e-01,  7.3687e-01,  3.8429e-02,  ...,  6.1745e-02,\n",
       "            1.7216e-01,  1.0262e+00]],\n",
       "\n",
       "         [[-2.5906e-01, -3.0687e-01, -4.4343e-03,  ..., -3.5072e-01,\n",
       "            1.3348e-02, -2.6978e-01],\n",
       "          [-3.2780e-01, -7.7524e-02, -3.4371e-01,  ...,  6.5466e-02,\n",
       "            8.6269e-01,  7.0336e-01],\n",
       "          [ 1.2326e+00, -9.8809e-02,  1.0411e+00,  ...,  4.5361e-01,\n",
       "            3.9660e-01,  9.1754e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.5480e-01, -1.8566e-01,  7.8025e-01,  ...,  2.9247e-01,\n",
       "           -6.8382e-02,  1.8960e-01],\n",
       "          [-3.7154e-02,  5.6497e-01,  2.6911e+00,  ..., -8.8050e-01,\n",
       "           -1.2558e-01,  4.6709e-01],\n",
       "          [ 1.2033e-01,  1.0071e+00,  8.5917e-01,  ...,  7.6670e-02,\n",
       "            1.3672e+00,  3.2556e-01]],\n",
       "\n",
       "         [[-3.2578e-01,  9.4770e-02, -1.4636e-01,  ..., -2.2955e-02,\n",
       "            1.5155e-01,  4.8268e-01],\n",
       "          [ 4.0002e-01,  5.3196e-01,  8.8704e-01,  ...,  9.2545e-01,\n",
       "           -1.4439e-01,  1.3301e-01],\n",
       "          [ 5.5740e-01,  1.6407e-01,  1.9794e-01,  ..., -1.3750e-01,\n",
       "            1.1034e+00, -2.0546e-01]],\n",
       "\n",
       "         [[-1.8385e-01, -1.8681e-01,  1.8654e-01,  ..., -1.1677e-01,\n",
       "            1.5978e-01, -5.1917e-01],\n",
       "          [-1.9319e-01,  4.1791e-01, -7.3156e-01,  ..., -1.7103e+00,\n",
       "            6.9156e-01, -3.0411e-01],\n",
       "          [ 2.2116e-01,  6.3451e-01, -6.6933e-01,  ..., -2.5200e-01,\n",
       "           -9.3288e-02, -8.5001e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[-0.7206, -2.1482,  2.4563,  ..., -0.7363,  0.8447,  4.8627],\n",
       "          [-1.4392, -3.9409,  2.9583,  ..., -2.5154,  1.7136,  5.2991],\n",
       "          [-0.6245, -3.6677,  2.2288,  ..., -2.3787,  0.4622,  4.5631]],\n",
       "\n",
       "         [[-1.3212,  2.5133,  1.7003,  ..., -2.2046, -0.3086,  1.8918],\n",
       "          [ 1.3567,  2.6311,  2.2400,  ..., -3.7483,  1.2034,  2.6933],\n",
       "          [ 0.0891,  2.5762,  1.1811,  ..., -1.7708, -0.1993,  2.8026]],\n",
       "\n",
       "         [[-1.9414, -0.9064,  1.7444,  ...,  1.1056, -1.6696, -0.0149],\n",
       "          [-0.9353, -0.9198,  4.6647,  ...,  1.4589, -2.5924, -1.2388],\n",
       "          [-2.1333, -3.2692,  6.8476,  ...,  0.4612, -1.4618, -1.6623]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.2400,  0.1360, -1.2109,  ...,  0.5840,  0.9495,  0.8394],\n",
       "          [ 4.6414,  0.0883, -1.8303,  ...,  2.0439,  1.2362, -0.4103],\n",
       "          [ 3.6453, -2.6625, -3.7483,  ...,  0.5484,  1.3054, -2.0253]],\n",
       "\n",
       "         [[ 0.7361,  2.3854, -0.3570,  ...,  1.2419, -0.3712, -0.5988],\n",
       "          [ 0.8659,  0.2898, -1.1050,  ...,  0.8604, -0.5407, -0.6042],\n",
       "          [ 1.7891,  1.0807, -0.0354,  ..., -0.4279, -1.4817, -0.0892]],\n",
       "\n",
       "         [[-1.1368, -0.4235,  3.7816,  ...,  3.0852,  0.0456, -3.1362],\n",
       "          [-2.3722,  0.6491,  3.3101,  ...,  2.5288,  1.6569, -6.0176],\n",
       "          [ 0.1968,  0.7959,  2.6353,  ...,  1.4341,  1.3594, -5.2555]]]],\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[ 0.4314,  0.1718, -0.1807,  ..., -0.0380,  0.1750,  0.4008],\n",
       "          [ 1.4003, -0.5630,  0.5693,  ..., -0.7838,  0.1250, -1.5008],\n",
       "          [ 1.8698, -0.8036,  0.0354,  ..., -0.0528,  1.5368, -1.2393]],\n",
       "\n",
       "         [[-0.4235, -0.0179, -0.0654,  ..., -0.5167,  0.0804,  0.0405],\n",
       "          [ 0.7217,  1.0684,  1.6710,  ..., -0.2875,  0.4529,  0.9604],\n",
       "          [ 0.2958, -0.3368,  0.0809,  ...,  1.0616, -0.0650,  0.4029]],\n",
       "\n",
       "         [[ 0.4237, -0.2578,  0.1755,  ...,  0.2702,  0.0300, -0.0391],\n",
       "          [ 0.5426, -0.6842,  0.6121,  ..., -0.3687,  0.6532, -0.3820],\n",
       "          [-0.8373,  0.3010,  0.9241,  ..., -0.5634, -0.0865,  1.3496]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.3083,  0.2435, -0.0045,  ...,  0.0418,  0.2753, -0.3342],\n",
       "          [-0.8674, -0.1467,  0.2188,  ..., -0.0410,  1.5611,  1.6667],\n",
       "          [-0.8920,  1.6260, -0.6515,  ...,  0.0079,  1.6497,  0.0646]],\n",
       "\n",
       "         [[-0.8675,  0.1390,  0.2819,  ...,  0.3134, -0.3419,  0.2844],\n",
       "          [-0.9365,  0.3624, -1.3479,  ..., -0.4788,  2.4429,  2.1595],\n",
       "          [ 0.2612,  1.6703, -1.2963,  ..., -0.8875,  2.5364, -0.2858]],\n",
       "\n",
       "         [[ 0.1846,  0.0720,  0.1492,  ..., -0.0607,  0.1952, -0.0262],\n",
       "          [-1.7174,  0.0807,  0.1438,  ...,  1.7493,  1.7288, -1.0485],\n",
       "          [-0.8292, -0.3194,  0.1608,  ...,  1.6255,  0.9219,  0.1098]]]],\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[ 1.3257, -0.8196, -0.2124,  ..., -1.0142, -3.1781,  2.3769],\n",
       "          [ 1.3603, -0.0641, -0.4320,  ..., -0.5050, -3.0924,  1.6761],\n",
       "          [ 0.9356, -2.5032,  1.2484,  ..., -1.6127, -2.4976,  4.1605]],\n",
       "\n",
       "         [[-1.7169, -3.0834,  1.8693,  ..., -2.6661, -1.0471, -3.2202],\n",
       "          [-0.4060, -2.7511,  0.8360,  ..., -2.1630, -0.8562, -3.0712],\n",
       "          [-0.8588, -2.3762,  0.6672,  ..., -1.7187, -2.6128, -5.7019]],\n",
       "\n",
       "         [[ 1.2122,  2.4483, -0.9281,  ..., -2.7331,  2.5092,  0.2937],\n",
       "          [ 2.8382,  2.6927,  0.2325,  ..., -3.1310,  4.0178,  0.1129],\n",
       "          [ 1.1279,  1.8643, -0.4522,  ..., -4.2642,  3.8279, -0.5332]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.1209,  1.0437,  5.6006,  ...,  0.6816,  4.0517,  4.6640],\n",
       "          [ 2.3171,  0.7839,  7.3524,  ...,  0.2599,  5.5568,  4.0186],\n",
       "          [ 1.8932,  1.6878,  7.6357,  ..., -0.1468,  4.2484,  3.8368]],\n",
       "\n",
       "         [[-3.2978, -4.0699, -3.2580,  ..., -3.8277,  6.0369, -0.5158],\n",
       "          [-6.1726, -3.6053, -2.8903,  ..., -4.1328,  5.3314, -3.1794],\n",
       "          [-7.5512, -1.7208, -4.7651,  ..., -2.2106,  4.4853, -3.1378]],\n",
       "\n",
       "         [[-0.3461,  0.1649,  0.7797,  ..., -0.8650,  0.6660, -1.2875],\n",
       "          [-1.4934,  0.4488,  0.4491,  ..., -1.8348,  1.7027, -1.0833],\n",
       "          [-0.5188,  2.3413,  1.2892,  ..., -3.3438,  0.5838,  0.1257]]]],\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[ 0.0988, -0.2345,  0.1208,  ..., -0.1315, -0.0489, -0.0851],\n",
       "          [-0.9021,  1.2711, -0.2253,  ..., -1.2801, -1.9805, -1.6422],\n",
       "          [-0.3958, -0.5384, -0.4681,  ..., -2.1485, -0.5841, -1.5738]],\n",
       "\n",
       "         [[ 0.3891,  0.0942,  0.1836,  ...,  0.2026,  0.1283,  0.1138],\n",
       "          [ 0.3162,  0.0132,  0.3959,  ...,  1.2821,  0.2995,  0.1743],\n",
       "          [-0.1306, -0.9501,  0.5602,  ...,  0.0062,  0.0568, -0.2177]],\n",
       "\n",
       "         [[-0.0819, -0.0529,  0.4681,  ..., -0.1966, -0.1232, -0.3412],\n",
       "          [-0.6708,  0.2237,  1.4600,  ...,  0.0530, -0.2534, -0.0525],\n",
       "          [-1.4939,  0.4971,  1.5396,  ..., -1.1053,  0.2999,  1.2301]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0751, -0.1934,  0.3423,  ...,  0.3815, -0.0086, -0.0373],\n",
       "          [ 1.7372, -0.6110, -0.1230,  ..., -0.5019,  0.6087, -0.5836],\n",
       "          [ 0.9286, -0.7183,  0.7157,  ...,  0.8590,  0.0451,  0.4444]],\n",
       "\n",
       "         [[ 0.3582,  0.0176, -0.0468,  ...,  0.0251, -0.0193, -0.2520],\n",
       "          [-0.0217, -0.6943,  0.0690,  ..., -0.0147,  0.5177, -0.6382],\n",
       "          [ 0.2091, -0.2592,  0.2982,  ...,  0.7618, -0.8363,  0.1622]],\n",
       "\n",
       "         [[ 0.6501,  0.0078,  0.3283,  ..., -0.4807, -0.3116, -0.2188],\n",
       "          [ 1.5021, -0.3445,  0.6107,  ..., -0.2820, -1.6546, -0.1526],\n",
       "          [-0.2149,  0.4061,  0.3759,  ...,  0.1960, -0.2949, -0.3699]]]],\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[ 4.8005,  1.9221,  1.4264,  ...,  0.0999,  1.6065, -3.7921],\n",
       "          [ 4.7346,  2.3640,  1.4977,  ...,  1.3064,  3.2114, -5.6001],\n",
       "          [ 4.0628,  3.5277,  1.5057,  ..., -0.1524,  1.8610, -3.5418]],\n",
       "\n",
       "         [[ 0.2776, -0.8845, -1.0596,  ...,  0.4357, -1.5099,  0.6925],\n",
       "          [-0.2507,  0.8683, -0.3871,  ...,  1.0732,  0.7684, -0.1606],\n",
       "          [-0.4794, -0.0239, -1.5768,  ...,  1.3019, -0.7780, -0.8481]],\n",
       "\n",
       "         [[-0.4850, -2.6387,  1.2071,  ..., -0.4799, -1.2840,  3.8845],\n",
       "          [-1.6062, -2.1877,  2.2962,  ..., -1.7613, -1.5843,  1.4165],\n",
       "          [-2.1722, -1.6942,  3.3543,  ..., -2.0633, -1.1571,  2.5823]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.1888, -0.4904,  2.9781,  ...,  4.3950, -3.9056,  1.7451],\n",
       "          [-2.4541, -1.5105,  3.1370,  ...,  4.8327, -4.5772,  2.1135],\n",
       "          [-1.9819, -1.3866,  2.1974,  ...,  4.6639, -4.3567,  2.5532]],\n",
       "\n",
       "         [[-1.7403, -1.3375, -1.4967,  ...,  0.7455, -0.1436,  1.0614],\n",
       "          [-2.1570,  0.2790, -2.2994,  ..., -1.0315, -0.2383,  0.3047],\n",
       "          [-1.2453, -0.3504, -2.6833,  ...,  0.6064,  0.8652,  0.9225]],\n",
       "\n",
       "         [[ 1.5765, -1.9364, -0.8832,  ..., -2.5267,  0.8024,  1.6314],\n",
       "          [ 0.4801, -2.4459,  0.2715,  ..., -2.2275,  0.0374,  2.4736],\n",
       "          [ 1.9105, -1.9401, -1.0859,  ..., -1.5926,  2.3140,  2.4254]]]],\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[-0.0828,  0.3216, -0.1545,  ...,  0.1010,  0.2321, -0.1554],\n",
       "          [-0.2992,  1.0484,  0.0664,  ...,  0.2976,  0.3880, -0.4517],\n",
       "          [ 0.0100,  1.3551, -0.5024,  ...,  0.1703, -0.6829, -0.0499]],\n",
       "\n",
       "         [[ 0.7000, -0.8289,  0.1825,  ..., -0.1685,  0.1057,  0.1835],\n",
       "          [ 3.1621,  3.4004, -0.9454,  ...,  0.0538,  0.5638, -1.0286],\n",
       "          [ 0.3159, -0.2175, -1.1374,  ...,  0.2330, -0.2405, -2.2402]],\n",
       "\n",
       "         [[ 0.3428,  0.1783,  0.2211,  ..., -0.1806, -0.3621, -0.0104],\n",
       "          [-0.8164, -0.7513, -0.3240,  ...,  0.5009, -0.8666, -0.5655],\n",
       "          [-0.1845, -0.2289, -0.8321,  ...,  0.2238, -1.9211, -1.0293]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0972, -0.0828,  0.2318,  ...,  0.3709, -0.1759,  0.3150],\n",
       "          [ 0.1405, -0.1156,  0.0154,  ...,  0.4349, -0.5535, -0.4216],\n",
       "          [ 0.2031,  0.8553, -0.9984,  ...,  1.5074,  0.1598, -1.3276]],\n",
       "\n",
       "         [[ 0.1456,  0.7441, -0.2468,  ..., -0.2520, -0.2243, -0.1426],\n",
       "          [-0.2201,  1.8679, -0.5301,  ...,  0.5502,  0.3638,  0.9540],\n",
       "          [ 0.9049,  0.6879, -0.4444,  ...,  1.4004,  0.2113, -0.0486]],\n",
       "\n",
       "         [[-0.0805, -0.7037, -0.2688,  ...,  0.4930,  0.0382, -0.1140],\n",
       "          [ 0.9070,  0.9860,  0.6474,  ..., -0.3189, -0.8436, -0.3797],\n",
       "          [ 0.1807,  0.3057,  0.0908,  ...,  0.5212, -0.5655, -0.3455]]]],\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[ 0.9914, -3.8655,  1.1647,  ...,  0.2129, -2.0218, -1.6582],\n",
       "          [ 1.7764, -3.1136, -0.2154,  ...,  0.7212, -2.1604, -2.5660],\n",
       "          [ 1.6121, -1.3235, -1.5122,  ...,  1.6818, -2.2745, -0.9586]],\n",
       "\n",
       "         [[-1.0232,  0.2011, -1.1907,  ...,  0.5936,  0.6257, -1.9987],\n",
       "          [-1.5305, -0.6255, -1.7554,  ...,  1.4718,  0.2522, -1.5392],\n",
       "          [-2.1742, -1.4884, -2.3631,  ...,  1.0243,  1.5709, -2.2364]],\n",
       "\n",
       "         [[ 1.7152,  0.8467,  1.4190,  ..., -1.6095,  1.2332, -0.5708],\n",
       "          [ 2.0481,  1.5499,  0.8855,  ..., -1.0285,  1.8028, -0.4079],\n",
       "          [ 0.7063, -0.6586,  0.5179,  ...,  0.0575,  0.3153,  0.4170]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0684, -0.3693, -2.1642,  ...,  0.8941, -0.0841, -2.6501],\n",
       "          [-0.5841,  0.4781, -3.0249,  ...,  1.2694, -0.8835, -0.7672],\n",
       "          [ 0.8417, -1.6987, -2.8541,  ...,  2.7497, -1.9994, -0.9857]],\n",
       "\n",
       "         [[ 0.0249,  0.3317,  2.0640,  ...,  1.1151, -1.2843,  1.8154],\n",
       "          [-0.2603,  0.1476,  2.5707,  ...,  0.8776, -0.9687,  1.2925],\n",
       "          [-1.6721,  0.7676,  2.2378,  ...,  1.7557, -1.4192,  1.9923]],\n",
       "\n",
       "         [[-0.9142, -0.7679,  1.4972,  ...,  0.4755,  1.5585, -1.0513],\n",
       "          [ 1.5796, -0.5195,  1.9219,  ...,  0.5607,  0.6771, -1.5210],\n",
       "          [ 1.6671, -1.8094,  0.9295,  ...,  0.2907,  1.2194, -2.5560]]]],\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[-0.3907, -0.1438,  0.2224,  ..., -0.2509, -0.2073, -0.0588],\n",
       "          [ 0.7580,  0.6797, -0.6391,  ...,  2.0245, -0.0164,  1.5631],\n",
       "          [ 0.1311,  1.6071, -1.2071,  ...,  0.6550,  1.5246,  0.6620]],\n",
       "\n",
       "         [[ 0.2599,  0.0835,  0.2659,  ...,  0.4427,  0.0219, -0.2114],\n",
       "          [ 1.4641,  0.8252, -0.3339,  ...,  0.0985, -0.4290, -0.4615],\n",
       "          [ 0.0530,  0.2761, -0.1718,  ...,  0.0357, -0.5149, -0.3823]],\n",
       "\n",
       "         [[-0.3639, -0.2179, -0.0226,  ...,  0.4246,  0.5438,  0.0986],\n",
       "          [-0.3505, -0.0401, -0.3959,  ...,  0.0226,  1.0368, -1.2793],\n",
       "          [-0.9729,  0.0342,  1.2838,  ...,  0.6592, -1.0443,  0.8706]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.1288,  0.2051, -0.2297,  ...,  0.4998, -0.1290, -0.0505],\n",
       "          [ 1.8027, -0.4117, -0.0571,  ...,  1.2912,  0.6321, -0.3637],\n",
       "          [ 0.4132, -0.4592, -0.3533,  ...,  1.2602,  1.1856, -0.2650]],\n",
       "\n",
       "         [[ 0.0669, -0.1721,  0.0930,  ..., -0.0884,  0.0849, -0.1647],\n",
       "          [ 0.3092, -0.8743,  0.3401,  ..., -0.1370, -0.1703,  0.2102],\n",
       "          [ 0.6618, -0.4608, -0.1747,  ..., -0.3474,  0.5050, -1.4549]],\n",
       "\n",
       "         [[ 0.2962, -0.0774,  0.2948,  ...,  0.2317, -0.2800, -0.2325],\n",
       "          [-0.3007,  1.1047, -1.2200,  ...,  0.3238, -0.1493,  0.1731],\n",
       "          [ 0.8326, -0.1344, -0.5123,  ..., -0.2343, -0.4823,  0.2157]]]],\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[ 2.5038,  3.4586, -3.7075,  ...,  1.4133,  1.9273,  2.5214],\n",
       "          [ 1.6702,  3.7563, -1.9723,  ...,  0.6786,  1.8990,  3.7752],\n",
       "          [ 3.6071,  4.4562, -3.7142,  ..., -0.1502,  1.2641,  2.9376]],\n",
       "\n",
       "         [[ 1.2377, -0.3802, -0.6553,  ...,  0.0058, -1.4715,  1.2345],\n",
       "          [ 0.7600,  0.8965, -0.7876,  ..., -0.5227, -1.5307, -0.3466],\n",
       "          [ 1.2803,  1.6039, -1.1612,  ..., -1.7965, -1.4049, -0.6149]],\n",
       "\n",
       "         [[-1.0538,  1.4529, -0.7488,  ...,  0.8023, -1.6731, -1.0616],\n",
       "          [-0.1544,  0.8507, -1.9240,  ..., -0.1750,  0.4614, -1.1202],\n",
       "          [-1.0327,  1.6173, -1.8637,  ..., -1.9644, -0.0909, -2.1325]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.5355,  2.0701, -1.8927,  ...,  0.4516,  0.4799, -0.0666],\n",
       "          [ 0.2565,  2.1518, -2.2253,  ...,  0.8308,  1.2320, -0.6106],\n",
       "          [ 0.9301,  2.6947, -1.5780,  ...,  0.8879,  1.2226, -1.4376]],\n",
       "\n",
       "         [[ 2.5786, -1.4676, -0.9786,  ..., -0.3752, -1.0672,  1.6848],\n",
       "          [ 1.3385, -0.3172, -0.8146,  ..., -1.4779, -2.3687,  2.0326],\n",
       "          [ 0.4004,  0.7238, -0.8952,  ..., -0.7588, -2.1461,  1.4419]],\n",
       "\n",
       "         [[ 0.2117,  0.5970,  0.0399,  ..., -0.9649,  0.6668,  0.9308],\n",
       "          [ 0.6636,  0.9509,  0.2587,  ..., -1.1077, -0.4238, -0.4098],\n",
       "          [ 1.1255, -0.4905,  0.0786,  ..., -2.2030, -0.8280, -1.3732]]]],\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[-0.0715, -0.0075, -0.0762,  ..., -0.2637,  0.3488,  0.1765],\n",
       "          [ 0.2571,  0.1925, -0.6760,  ..., -1.0140,  1.5934,  0.4894],\n",
       "          [ 0.1898,  0.0343,  0.8591,  ...,  0.8354, -1.1012, -0.8362]],\n",
       "\n",
       "         [[-0.4087, -0.3338,  0.2557,  ...,  0.4017, -0.1864, -0.0516],\n",
       "          [-1.4868,  0.5967,  0.3414,  ...,  0.0178, -0.3185,  0.0565],\n",
       "          [ 0.8895, -0.2213,  0.2042,  ..., -0.4333, -0.2712, -0.0689]],\n",
       "\n",
       "         [[-0.3990,  0.2006, -0.0184,  ..., -0.1686,  0.9466,  0.2233],\n",
       "          [-0.8810, -0.0652,  0.2961,  ...,  0.0911,  0.7881, -0.1667],\n",
       "          [-0.5810, -1.6313,  0.1749,  ..., -0.1219,  0.9679,  1.2112]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.1993, -0.3740, -0.1695,  ...,  0.1819, -0.8871,  0.5764],\n",
       "          [ 0.0632, -0.0858, -0.6865,  ...,  1.1456, -0.1467,  0.3776],\n",
       "          [ 0.3070,  0.4056, -0.6291,  ..., -0.1576,  0.5058, -0.0922]],\n",
       "\n",
       "         [[ 0.0088, -0.4263,  0.5461,  ...,  0.0266,  0.2421, -0.6215],\n",
       "          [ 0.0281, -0.7346,  0.5428,  ..., -0.7064, -0.2076,  0.1403],\n",
       "          [ 0.0693, -0.1438,  1.3233,  ...,  0.5165, -1.4457, -0.5058]],\n",
       "\n",
       "         [[-0.3093,  0.0487, -0.8679,  ...,  0.2690,  0.8558, -0.5511],\n",
       "          [ 0.6631, -0.4661,  0.0425,  ..., -0.3513,  1.4284, -0.4956],\n",
       "          [ 0.3450, -0.6826, -0.2332,  ...,  0.5436, -0.2233,  0.3421]]]],\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[ 7.3552e-01, -8.5720e-01, -9.0370e-01,  ...,  1.0635e+00,\n",
       "            1.0249e+00, -2.0900e+00],\n",
       "          [ 2.2306e+00, -5.3084e-01,  3.7442e-01,  ...,  1.9818e+00,\n",
       "            3.9495e-01, -9.2762e-01],\n",
       "          [ 1.7299e+00, -8.5852e-01,  1.9593e+00,  ...,  3.8149e+00,\n",
       "            9.3680e-01, -1.5130e-01]],\n",
       "\n",
       "         [[-1.4529e+00, -1.6380e+00,  1.1047e+00,  ..., -1.6019e-01,\n",
       "            1.9522e+00, -1.3809e+00],\n",
       "          [ 1.2482e+00, -1.6355e+00,  1.8930e+00,  ...,  1.0018e+00,\n",
       "            5.9401e-01, -1.1377e+00],\n",
       "          [-3.9495e-01, -1.3497e-01,  1.2050e+00,  ...,  4.9278e-01,\n",
       "            1.3714e-01, -1.3898e+00]],\n",
       "\n",
       "         [[ 1.2610e+00,  3.9557e-01,  4.6043e-01,  ..., -3.7645e-01,\n",
       "           -1.8073e-01,  8.4450e-01],\n",
       "          [-1.3420e+00, -2.0232e+00, -8.7752e-01,  ...,  3.1966e-02,\n",
       "            1.0019e-01,  3.3777e-01],\n",
       "          [-5.9113e-03,  6.9271e-01, -2.5425e-02,  ..., -2.4679e-01,\n",
       "           -9.0212e-01,  1.5444e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.4647e+00,  4.6071e-01,  1.2552e+00,  ..., -6.8515e-01,\n",
       "           -1.3793e+00,  9.1970e-01],\n",
       "          [ 2.2243e+00,  1.0068e+00,  1.0982e+00,  ..., -3.6623e-01,\n",
       "           -4.8897e-01,  1.2266e+00],\n",
       "          [ 2.8298e+00,  5.9390e-01,  1.4055e+00,  ..., -1.4585e+00,\n",
       "           -2.0858e+00,  1.0549e+00]],\n",
       "\n",
       "         [[-8.7609e-01,  8.9028e-01,  4.2761e-01,  ..., -2.6565e+00,\n",
       "            3.3079e-01, -4.3918e-01],\n",
       "          [-2.7865e+00, -8.7759e-02, -7.1284e-01,  ..., -2.5449e+00,\n",
       "           -8.7454e-01, -2.5194e-01],\n",
       "          [-3.4247e+00,  6.1047e-02,  1.9790e+00,  ..., -3.4126e+00,\n",
       "           -5.7368e-01, -2.9969e+00]],\n",
       "\n",
       "         [[ 7.5070e-01, -2.0674e+00,  1.4492e-01,  ..., -1.4327e-01,\n",
       "           -1.8009e+00, -1.7833e+00],\n",
       "          [ 1.1132e+00, -1.7145e+00,  2.0979e+00,  ..., -2.4351e-04,\n",
       "           -3.3239e+00, -1.1588e+00],\n",
       "          [ 5.9335e-02, -1.2769e+00,  1.2510e+00,  ...,  3.4316e-01,\n",
       "           -2.7382e+00, -1.1199e+00]]]], grad_fn=<PermuteBackward0>), tensor([[[[ 0.8072,  0.5092, -0.6354,  ..., -0.5212, -0.5803,  0.8111],\n",
       "          [-0.6698,  0.3842,  1.0618,  ..., -0.9148, -0.3353, -1.2977],\n",
       "          [ 0.9089,  0.4807,  0.9417,  ..., -0.2400, -0.9247, -0.8791]],\n",
       "\n",
       "         [[ 0.9087, -0.2302, -0.3534,  ..., -0.3891, -0.2120, -0.5672],\n",
       "          [ 0.0424, -0.8839,  0.1662,  ..., -0.8309,  0.9935, -0.5813],\n",
       "          [-0.2482,  0.8189, -0.9376,  ...,  0.4797,  1.0459, -0.5272]],\n",
       "\n",
       "         [[-0.7280, -0.0217,  0.8019,  ..., -0.7023, -0.3774, -0.0198],\n",
       "          [ 1.0591,  0.4125,  2.0496,  ...,  0.3591, -1.0001, -0.2726],\n",
       "          [ 1.3112,  0.8660,  0.0646,  ...,  0.0917, -0.9415, -0.4037]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.2867,  0.2481,  0.2356,  ..., -0.5129,  0.0929,  0.1713],\n",
       "          [-1.4397,  0.8603,  0.6259,  ..., -0.5700,  0.6122,  1.4445],\n",
       "          [-0.5667,  0.8712,  1.0995,  ...,  0.3843, -0.0929,  0.9547]],\n",
       "\n",
       "         [[ 0.3296, -0.2511,  0.0046,  ..., -0.0313, -0.1814,  1.0549],\n",
       "          [ 1.1040, -1.1094,  0.4311,  ..., -0.9274, -0.6336, -0.2433],\n",
       "          [-0.1117, -1.4385,  0.0474,  ..., -0.7812,  0.8630, -0.7689]],\n",
       "\n",
       "         [[-0.3098, -0.1437, -0.3446,  ...,  0.1550, -0.0485, -0.1547],\n",
       "          [-0.1409, -0.3289, -1.2924,  ...,  1.3788, -0.2704, -0.6287],\n",
       "          [ 0.1587, -0.0854, -0.3155,  ...,  0.6377,  0.2692,  1.1020]]]],\n",
       "       grad_fn=<PermuteBackward0>))), hidden_states=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text-generation-news-gpt2-small-hungarian\n",
    "# Run time: 21m\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"NYTK/text-generation-news-gpt2-small-hungarian\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"NYTK/text-generation-news-gpt2-small-hungarian\")\n",
    "\n",
    "get_avg_res(tokenizer,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9276126429198216\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CausalLMOutputWithCrossAttentions(loss=None, logits=tensor([[[ -2.6028,  -3.4230,   2.0850,  ...,  -3.6229,  -5.5268,  -5.3679],\n",
       "         [ -3.4194,  -5.7300,  -1.9777,  ...,  -5.3644,  -8.9462,  -8.1705],\n",
       "         [ -2.5727,  -5.5653,  -2.8149,  ...,  -9.1339, -11.3441, -10.5183]]],\n",
       "       grad_fn=<UnsafeViewBackward0>), past_key_values=((tensor([[[[ 6.2375e-01, -5.4565e-01,  3.0739e+00,  ...,  1.1495e+00,\n",
       "            1.8797e-01, -1.0632e-01],\n",
       "          [ 1.6363e+00, -6.1063e-01,  9.6761e-01,  ..., -2.6795e-01,\n",
       "            1.7213e+00,  7.1853e-01],\n",
       "          [ 1.3586e+00, -4.7224e-01,  2.1549e+00,  ..., -1.0640e+00,\n",
       "            3.9966e+00,  9.6106e-01]],\n",
       "\n",
       "         [[-9.4393e-01,  8.7675e-01, -4.7710e-01,  ...,  2.6136e-01,\n",
       "           -1.0788e+00,  1.6523e+00],\n",
       "          [ 1.0532e+00,  1.3930e-01,  4.8374e-01,  ..., -4.1034e-01,\n",
       "            1.6854e-01,  1.6128e+00],\n",
       "          [-1.7038e+00, -5.0348e-01, -2.0477e+00,  ...,  5.4685e-01,\n",
       "           -2.0591e-01,  7.0547e-01]],\n",
       "\n",
       "         [[ 7.1422e-02, -9.5202e-01,  4.0295e-02,  ..., -2.1463e-01,\n",
       "           -4.7825e-01,  4.2391e-01],\n",
       "          [ 3.1921e-01, -2.8365e-01, -6.9381e-01,  ...,  8.3821e-01,\n",
       "           -2.4767e-01,  5.9031e-01],\n",
       "          [ 7.2238e-01, -1.7706e-01, -3.6869e-01,  ...,  4.5578e-01,\n",
       "           -8.7938e-01,  1.3660e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-3.8062e-01, -1.6011e+00,  5.4193e-01,  ...,  9.7771e-01,\n",
       "            1.0653e+00,  1.0639e-01],\n",
       "          [ 6.5785e-02,  2.4339e-01, -1.7281e+00,  ..., -3.6262e-01,\n",
       "           -1.1468e+00,  1.5245e+00],\n",
       "          [ 1.8957e-01, -1.2665e+00, -1.1422e-01,  ..., -1.0594e+00,\n",
       "           -3.1548e-01, -1.3249e-01]],\n",
       "\n",
       "         [[-1.3233e+00, -1.1539e+00,  1.1448e-03,  ...,  2.0463e-01,\n",
       "            9.6303e-01,  1.8891e+00],\n",
       "          [-1.3912e+00, -1.3908e+00, -1.2295e+00,  ..., -6.4174e-01,\n",
       "           -3.1377e-01,  2.9281e+00],\n",
       "          [-3.8406e-01, -6.1505e-01, -2.2239e+00,  ...,  5.3229e-01,\n",
       "            1.0974e-01,  3.8480e-01]],\n",
       "\n",
       "         [[ 2.0820e-01, -6.7147e-01, -4.2070e-01,  ...,  7.6141e-01,\n",
       "           -1.3450e+00, -3.6656e-01],\n",
       "          [-1.3251e+00, -1.2302e+00,  4.8925e-01,  ...,  4.5862e-01,\n",
       "            9.9661e-01,  4.0400e-01],\n",
       "          [-4.8235e-01,  4.4178e-01, -1.1103e+00,  ...,  2.1994e-01,\n",
       "           -7.9105e-01, -9.4663e-01]]]], grad_fn=<PermuteBackward0>), tensor([[[[-2.2096e-01,  2.9790e-02,  1.9352e+00,  ...,  1.5184e+00,\n",
       "           -8.1199e-01,  5.1127e-01],\n",
       "          [ 2.5921e-01,  4.2377e-01, -6.1661e-01,  ...,  1.6232e-01,\n",
       "           -3.6107e-01, -1.5603e-01],\n",
       "          [ 2.0300e-01, -7.9516e-02,  3.6350e-01,  ...,  6.6261e-01,\n",
       "           -3.2626e-01, -9.5416e-01]],\n",
       "\n",
       "         [[ 5.6781e-01,  6.1703e-01, -5.9093e-01,  ..., -1.0490e+00,\n",
       "           -2.4351e+00,  6.2173e-01],\n",
       "          [ 7.6286e-01,  3.3895e-01, -1.4609e-02,  ...,  2.9270e-04,\n",
       "            9.8819e-01,  5.9983e-02],\n",
       "          [ 5.2814e-01,  6.4524e-01,  5.8807e-01,  ...,  6.1709e-03,\n",
       "            2.7520e-01, -1.7552e+00]],\n",
       "\n",
       "         [[-2.2332e-01,  3.5077e-01, -4.2085e-01,  ...,  3.2281e-01,\n",
       "            1.2513e+00, -6.1096e-02],\n",
       "          [ 1.3651e-01,  1.6505e+00, -3.0495e-01,  ..., -3.7448e-01,\n",
       "            3.4497e-01,  5.9183e-01],\n",
       "          [ 1.1674e-01,  2.6048e-01, -1.0789e-01,  ...,  5.8588e-01,\n",
       "            1.3584e-01, -7.3560e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 5.3944e-01, -7.3866e-01,  1.0836e+00,  ...,  6.7530e-01,\n",
       "           -6.0165e-03, -9.3234e-01],\n",
       "          [ 6.2835e-02,  1.7686e-01,  1.5037e-01,  ..., -1.6986e-01,\n",
       "           -1.2045e+00, -4.0052e-01],\n",
       "          [ 6.1020e-02,  8.8410e-01, -1.3821e-01,  ..., -8.8379e-01,\n",
       "            5.3832e-01, -2.9687e-01]],\n",
       "\n",
       "         [[-9.5363e-01, -9.8127e-01, -4.5056e-01,  ...,  1.4683e+00,\n",
       "           -7.9004e-01,  1.0339e-02],\n",
       "          [ 1.6701e-01, -6.7778e-01,  1.3068e-01,  ..., -8.3533e-01,\n",
       "           -4.6782e-01,  8.3837e-01],\n",
       "          [-7.6420e-01, -2.3259e-01, -4.2228e-01,  ..., -9.3727e-02,\n",
       "            6.7295e-01,  1.1175e+00]],\n",
       "\n",
       "         [[ 4.5231e-01, -1.2049e-01,  6.6010e-01,  ..., -1.0013e+00,\n",
       "           -8.8782e-02,  1.1525e+00],\n",
       "          [ 9.6129e-01,  1.0122e-02, -2.7981e-01,  ..., -7.1538e-02,\n",
       "            7.4689e-01, -4.4911e-01],\n",
       "          [-1.2376e+00,  2.5838e-01, -6.9919e-01,  ..., -1.3850e+00,\n",
       "            3.0012e-03,  6.7146e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[ 0.7662, -0.8525,  1.2453,  ...,  0.8967, -0.2892,  1.4478],\n",
       "          [ 0.8890,  0.1315,  1.3691,  ...,  0.6543,  1.3647, -0.1541],\n",
       "          [-0.6541,  0.3583,  0.5013,  ...,  0.6502, -1.1483,  0.7470]],\n",
       "\n",
       "         [[ 0.2407,  0.1947,  0.1791,  ...,  0.4126, -0.8664, -0.5758],\n",
       "          [ 0.4348,  0.4061, -1.0195,  ...,  0.7294,  0.5207,  0.3027],\n",
       "          [ 0.5000, -0.5699, -0.8387,  ...,  1.6089, -0.2061,  0.3674]],\n",
       "\n",
       "         [[-1.8938,  0.1655, -0.1808,  ..., -0.2832, -0.8226, -0.4557],\n",
       "          [-0.1859,  0.2795,  0.4416,  ..., -0.7847,  0.1168,  0.4300],\n",
       "          [-0.6594,  0.2247, -0.0740,  ...,  0.1976, -0.4683,  0.8533]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.3832, -3.1182, -1.0184,  ..., -3.3511, -2.4409,  2.4360],\n",
       "          [ 1.1418,  1.9316, -0.1944,  ..., -0.5419, -2.5823,  0.0275],\n",
       "          [ 1.2908,  1.3702, -0.1983,  ...,  0.9099, -1.8570,  2.4653]],\n",
       "\n",
       "         [[ 1.0237,  0.9770, -0.5762,  ...,  0.6173, -0.6708, -0.8936],\n",
       "          [-0.5175, -0.0759, -0.3759,  ...,  0.4869, -0.7555, -0.6912],\n",
       "          [ 0.1956, -0.0275, -0.5852,  ..., -0.3480, -0.9025,  0.5203]],\n",
       "\n",
       "         [[-0.4331,  0.1453, -0.5516,  ..., -0.5894,  0.5776, -0.1485],\n",
       "          [ 0.0368, -0.5867, -0.1087,  ...,  0.1613,  1.2359,  1.0617],\n",
       "          [ 0.6321, -0.9272, -0.0732,  ...,  1.2181, -0.3757,  0.4657]]]],\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[-1.7044e-01,  7.5044e-01,  2.7417e-01,  ...,  9.6985e-01,\n",
       "           -1.7762e-01,  9.9284e-02],\n",
       "          [-1.7350e-01,  2.6092e-01,  1.3672e-01,  ...,  9.9309e-01,\n",
       "            6.5460e-01, -1.0195e+00],\n",
       "          [ 2.0857e-01,  1.3507e-03,  4.7190e-01,  ...,  6.5903e-01,\n",
       "            7.2403e-01,  3.5165e-03]],\n",
       "\n",
       "         [[ 9.5610e-01,  1.9151e-01, -4.3056e-01,  ..., -7.8354e-01,\n",
       "            3.2252e-01,  1.6003e-01],\n",
       "          [-2.5906e-01, -2.8665e-01,  2.6737e-01,  ..., -4.0652e-01,\n",
       "           -2.4542e-01,  1.9461e-01],\n",
       "          [-8.6133e-01,  1.3540e-01,  1.2451e-01,  ...,  1.1618e-02,\n",
       "            2.1120e-01, -3.8159e-02]],\n",
       "\n",
       "         [[ 5.2035e-01,  2.5164e-01,  1.1689e-01,  ...,  1.1899e+00,\n",
       "            4.9558e-01,  7.5744e-01],\n",
       "          [-1.5379e-02,  8.0986e-02, -4.7837e-01,  ...,  6.0798e-01,\n",
       "            8.7784e-01,  7.9804e-01],\n",
       "          [ 8.0720e-01, -4.4570e-01, -2.0481e-01,  ...,  7.3652e-01,\n",
       "            4.4252e-01,  6.5543e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.0177e+00, -2.2861e-01, -3.5656e-01,  ...,  5.7131e-02,\n",
       "           -8.1872e-01, -3.0537e-01],\n",
       "          [-7.6454e-01,  5.0483e-01,  5.9497e-01,  ...,  1.2377e-01,\n",
       "            1.0414e-01,  6.2263e-01],\n",
       "          [-3.4126e-01,  1.6588e-01, -4.6720e-01,  ..., -1.1136e-02,\n",
       "            2.3390e-01,  1.0400e-01]],\n",
       "\n",
       "         [[ 4.0492e-01, -1.6735e-01, -1.1627e-01,  ..., -3.2700e-01,\n",
       "           -2.6839e-01,  8.4322e-01],\n",
       "          [ 1.9733e-01, -4.4482e-01, -2.0321e-01,  ..., -2.5059e-01,\n",
       "            3.2584e-02, -3.0583e-01],\n",
       "          [ 1.8783e-01, -4.0418e-01,  7.7770e-02,  ..., -1.2304e-02,\n",
       "            2.3838e-01,  6.7408e-02]],\n",
       "\n",
       "         [[ 4.3421e-01, -5.8839e-02, -5.8273e-02,  ..., -6.7967e-03,\n",
       "           -9.1255e-02,  3.6778e-01],\n",
       "          [-1.5319e+00, -2.9504e-02,  7.6372e-01,  ..., -4.8337e-01,\n",
       "           -2.3313e-01,  2.1511e-01],\n",
       "          [ 1.7004e-01, -3.2434e-01,  1.3400e-01,  ...,  8.4263e-01,\n",
       "            3.2951e-01,  4.7806e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[-0.6783, -0.7971, -2.0368,  ...,  1.8143,  3.6002,  0.3934],\n",
       "          [-0.1285, -1.7919, -0.7490,  ...,  1.9382,  2.6734,  1.3568],\n",
       "          [ 0.0839, -0.6745, -4.5863,  ...,  4.2591,  3.1812,  1.2905]],\n",
       "\n",
       "         [[-0.9099,  1.5958,  1.6294,  ..., -0.7606, -0.1488,  1.2832],\n",
       "          [ 0.1610,  0.6734,  3.1006,  ..., -0.6207, -1.1282,  1.2082],\n",
       "          [-0.5329,  0.0844,  3.0328,  ..., -2.1772, -0.5895,  2.7906]],\n",
       "\n",
       "         [[ 1.7450,  0.9164,  1.2603,  ...,  0.6083, -0.3467, -2.4273],\n",
       "          [ 1.2627,  1.4142,  0.7177,  ...,  0.5561, -0.6832, -3.1447],\n",
       "          [ 0.3349, -0.4210,  0.0963,  ...,  0.6800, -0.3861, -2.9323]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.3030,  0.7264, -0.2224,  ..., -0.3215,  0.3341, -0.9161],\n",
       "          [-0.1077,  0.0800, -0.1926,  ...,  0.7186,  0.1526,  0.1928],\n",
       "          [ 1.2473, -0.1727, -0.3425,  ..., -0.2912,  0.3943, -0.5352]],\n",
       "\n",
       "         [[ 0.6910, -2.9053, -1.2360,  ..., -0.1589, -0.4084,  3.0092],\n",
       "          [ 0.4676, -3.2118, -2.0249,  ..., -0.2784, -0.0799,  1.3137],\n",
       "          [ 0.6321, -3.8695, -1.0654,  ...,  0.0861, -0.7540,  0.2534]],\n",
       "\n",
       "         [[-0.8977,  0.0855,  0.9803,  ...,  0.7252, -1.3167, -2.4551],\n",
       "          [-0.3472, -0.9807,  0.9321,  ...,  0.8323, -1.0485, -2.1486],\n",
       "          [-0.5768,  0.0064, -0.5928,  ...,  1.1817, -2.1517, -2.2583]]]],\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[-0.4502, -0.1632,  0.1850,  ...,  0.5937,  0.2020,  0.2202],\n",
       "          [ 0.1659,  0.2261,  0.0585,  ..., -0.2903,  0.3373, -0.3109],\n",
       "          [-0.3982,  0.1453,  0.1709,  ...,  0.1119, -0.3641, -0.1016]],\n",
       "\n",
       "         [[-0.2755, -0.0715, -0.4086,  ...,  0.0667, -0.2529, -0.4335],\n",
       "          [-0.4988,  0.3587, -0.4743,  ..., -0.6596,  0.2594, -0.0342],\n",
       "          [-0.6609,  1.0726, -0.6196,  ...,  0.5178, -0.5526, -0.2236]],\n",
       "\n",
       "         [[ 0.2845,  0.0421, -0.0371,  ...,  0.1093, -0.2239,  0.0558],\n",
       "          [ 0.5755,  0.1785,  0.3424,  ...,  0.4330, -0.0711, -0.2856],\n",
       "          [ 0.4557, -0.1145,  0.5322,  ..., -0.7561, -0.6413, -0.1426]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.3200, -0.0824, -0.3406,  ..., -0.0955, -0.0091, -0.1237],\n",
       "          [ 0.4493, -0.7910,  0.5308,  ..., -0.3899, -0.0270,  0.2888],\n",
       "          [ 0.3043, -0.1705, -0.1820,  ..., -1.1390,  0.3250,  0.0781]],\n",
       "\n",
       "         [[ 0.3225,  0.3176, -0.2193,  ...,  0.0133, -0.1512,  0.2459],\n",
       "          [-0.1791,  0.2597, -0.5080,  ..., -0.1464,  0.2603,  0.8005],\n",
       "          [ 0.1597, -0.4597, -0.0409,  ..., -0.1338,  0.1769, -0.4889]],\n",
       "\n",
       "         [[ 0.6295,  0.3431, -0.1662,  ..., -0.1798, -0.1001,  0.7053],\n",
       "          [-0.4383,  0.3939, -0.1983,  ...,  0.8234, -0.4214, -0.4827],\n",
       "          [-0.2195,  0.6366, -0.5190,  ..., -0.1710,  0.3175,  0.5354]]]],\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[ 3.1593,  1.2657, -1.1794,  ...,  3.3669,  3.0312, -1.9436],\n",
       "          [ 2.8160,  1.0412, -1.2896,  ...,  2.2159,  1.8240, -3.3269],\n",
       "          [ 2.3732,  0.6968, -1.7260,  ...,  1.8172,  2.5481, -3.9909]],\n",
       "\n",
       "         [[ 3.9472,  5.3729, -2.3114,  ...,  0.1065, -1.8150,  3.2077],\n",
       "          [ 5.0017,  3.8030, -3.1535,  ...,  2.5332, -1.1796,  1.9321],\n",
       "          [ 5.4702,  4.5891, -2.2237,  ...,  0.0534, -1.2503,  2.4071]],\n",
       "\n",
       "         [[ 0.2503, -0.2008, -0.9552,  ...,  1.4368,  1.6768,  1.0991],\n",
       "          [ 0.8353,  0.2747, -0.6044,  ...,  2.2357,  1.1469,  1.3910],\n",
       "          [ 1.8979, -0.7707,  0.0724,  ...,  2.2976, -0.2000,  1.7787]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.0870,  2.3412, -1.0371,  ...,  0.9335, -0.7930,  0.9975],\n",
       "          [ 1.3648,  3.7964, -0.8610,  ...,  0.2821, -2.2241,  0.3337],\n",
       "          [ 0.7966,  2.8319, -1.6873,  ...,  1.0410, -0.7967,  1.3706]],\n",
       "\n",
       "         [[ 0.0552, -0.0785,  1.6636,  ..., -0.0090,  1.6131, -0.4647],\n",
       "          [-0.1873,  0.0394,  1.9711,  ...,  1.3982,  0.3406, -1.4195],\n",
       "          [ 0.6376, -0.0282,  2.0911,  ..., -0.1221,  0.3076,  1.8418]],\n",
       "\n",
       "         [[ 4.7429, -3.7870, -3.6320,  ...,  1.8173, -0.1100,  0.3638],\n",
       "          [ 4.0433, -2.2957, -4.2062,  ...,  1.7652, -0.6867, -0.1717],\n",
       "          [ 4.9952, -1.6004, -1.8201,  ...,  3.0788, -1.3416, -1.9736]]]],\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[-0.1327, -0.4038,  0.1224,  ..., -0.0980, -0.3469, -0.2405],\n",
       "          [ 0.3448, -0.2603,  1.0894,  ...,  0.4495,  0.4528,  0.7437],\n",
       "          [-0.3972, -0.5352,  0.1055,  ..., -0.3426,  0.0240, -0.0635]],\n",
       "\n",
       "         [[-0.1301, -0.1561, -0.1722,  ..., -0.2163,  0.1126,  0.2534],\n",
       "          [-0.3049,  0.0493,  0.3652,  ...,  0.1460, -0.2959,  0.1524],\n",
       "          [-0.7034,  0.6386, -0.4666,  ...,  1.4639,  0.4073, -0.5099]],\n",
       "\n",
       "         [[ 0.3281, -0.3663,  0.0909,  ...,  0.1089, -0.6864, -0.4526],\n",
       "          [-0.0115, -0.2171, -0.3144,  ..., -0.8449, -0.3720, -0.9911],\n",
       "          [-0.9010,  0.4408, -0.1169,  ...,  0.3259, -1.0112, -0.8061]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.3347, -0.1026, -0.1092,  ...,  0.3754, -0.0143, -0.5549],\n",
       "          [ 0.2573,  0.1862,  0.1251,  ..., -0.5696,  0.6495,  0.1938],\n",
       "          [-0.4254,  0.4216,  0.5185,  ...,  0.0215, -0.5796,  0.6360]],\n",
       "\n",
       "         [[-0.1226, -0.2078,  0.1426,  ..., -0.4286,  0.7075,  0.1809],\n",
       "          [ 0.5555,  0.1442, -0.2696,  ...,  0.0377,  1.1542, -0.4860],\n",
       "          [-0.6473, -0.6351, -0.0810,  ..., -1.3632,  0.4141,  0.5775]],\n",
       "\n",
       "         [[-0.1444, -0.1109, -0.3586,  ..., -0.1610,  0.0963,  0.0285],\n",
       "          [-0.4701, -0.4801,  1.0272,  ...,  0.5847,  0.4784, -0.0930],\n",
       "          [-0.6519,  0.3368, -0.3864,  ...,  0.3502,  0.1069, -0.5545]]]],\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[ 3.2793,  0.5287,  1.3850,  ...,  2.8751, -3.7055,  1.3234],\n",
       "          [ 2.7443,  0.1348,  2.6281,  ...,  3.2066, -3.9610,  1.5742],\n",
       "          [ 4.9373,  0.6759,  1.6744,  ...,  3.5796, -4.2189,  1.2200]],\n",
       "\n",
       "         [[ 2.0251, -1.1022, -0.8807,  ..., -0.6222, -0.7320, -1.7062],\n",
       "          [ 2.4748, -2.2303, -0.3183,  ..., -0.5924, -0.2043, -2.4669],\n",
       "          [ 3.0327, -2.4160,  0.7927,  ...,  0.3040,  0.1532, -2.2709]],\n",
       "\n",
       "         [[-0.6479,  1.2205,  4.9711,  ..., -1.9371,  0.7503,  1.3606],\n",
       "          [ 1.6782,  1.2767,  4.4239,  ..., -2.0586,  1.6433,  2.2601],\n",
       "          [ 0.5466, -0.5950,  4.0898,  ..., -1.6422,  1.1576,  2.3663]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.1009,  0.2973, -1.2547,  ..., -0.7645, -0.7117, -0.9954],\n",
       "          [ 1.1305, -0.5340, -1.8415,  ...,  0.1754, -0.0929, -3.1762],\n",
       "          [ 0.3598,  0.6354, -1.2117,  ..., -2.6323, -0.2951, -2.8584]],\n",
       "\n",
       "         [[ 1.6686,  0.6180, -2.5473,  ...,  3.5722,  0.7421, -4.0416],\n",
       "          [ 3.0467, -0.6668, -4.6328,  ...,  4.3009,  2.2006, -2.7706],\n",
       "          [ 1.6069,  0.4840, -3.2547,  ...,  5.1682,  1.4724, -2.9868]],\n",
       "\n",
       "         [[-0.4879,  2.2826,  1.4314,  ...,  1.1450, -0.0477, -1.0576],\n",
       "          [-0.3575,  1.0041,  0.1194,  ...,  2.9115,  0.3463,  0.6266],\n",
       "          [ 0.6261,  1.4451,  0.0569,  ...,  3.3035,  2.5007, -0.5463]]]],\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[-1.6007e-01, -1.0041e-01, -2.5995e-01,  ...,  9.7046e-02,\n",
       "            1.0164e-01,  6.4805e-02],\n",
       "          [ 5.2276e-01, -8.3904e-01,  4.2521e-01,  ...,  1.5026e+00,\n",
       "            3.6261e-01,  3.3412e-01],\n",
       "          [ 6.4370e-01,  3.2315e-02, -6.0680e-02,  ...,  1.8125e+00,\n",
       "           -9.9208e-03,  8.2831e-01]],\n",
       "\n",
       "         [[-1.4074e-01,  1.8206e-02,  1.1773e-01,  ..., -2.3147e-01,\n",
       "           -2.2761e-01,  5.2432e-01],\n",
       "          [-1.0498e+00,  8.4587e-03, -5.6029e-02,  ..., -1.3840e+00,\n",
       "            9.3920e-02, -9.6145e-01],\n",
       "          [-3.8264e-01, -1.1974e+00,  2.7637e-03,  ...,  6.8100e-01,\n",
       "            6.4320e-01, -1.5847e+00]],\n",
       "\n",
       "         [[-3.8716e-01, -2.2890e-02,  4.6454e-02,  ...,  9.4881e-02,\n",
       "            2.9365e-01,  7.6504e-01],\n",
       "          [ 2.4645e-01, -3.0406e-01,  4.6706e-01,  ..., -5.4539e-01,\n",
       "           -4.3155e-01,  2.0551e-01],\n",
       "          [ 6.6434e-03, -4.5285e-01,  2.8957e-01,  ..., -1.3099e-01,\n",
       "           -9.8856e-01, -1.2766e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-5.7346e-01,  5.6007e-01, -2.4524e-01,  ..., -3.4805e-01,\n",
       "            1.1303e-02,  3.5890e-01],\n",
       "          [-1.4221e+00, -1.1756e+00,  1.6407e-01,  ..., -5.9315e-01,\n",
       "            9.3816e-01,  7.8984e-01],\n",
       "          [-3.9892e-01, -8.3876e-01, -3.1787e-01,  ..., -8.1735e-01,\n",
       "            3.3841e-01, -1.2312e-01]],\n",
       "\n",
       "         [[-2.1824e-01,  2.6009e-01, -4.6720e-01,  ..., -2.0927e-01,\n",
       "            3.6534e-02, -1.5482e-04],\n",
       "          [ 8.2120e-02,  3.3990e-01,  9.9870e-01,  ..., -6.8781e-02,\n",
       "           -3.3205e-01,  3.0313e-01],\n",
       "          [ 4.3155e-01,  1.5442e+00,  8.5586e-01,  ...,  1.4897e-04,\n",
       "            7.0345e-03,  1.5715e-01]],\n",
       "\n",
       "         [[-5.6654e-01,  1.7651e-01, -3.7886e-01,  ..., -3.1215e-01,\n",
       "            1.2944e-01,  2.3331e-01],\n",
       "          [-1.5989e+00, -3.4389e-01, -5.6599e-01,  ..., -1.4004e-01,\n",
       "            9.0734e-01, -4.5086e-01],\n",
       "          [-1.3042e+00,  3.2003e-01, -4.5884e-01,  ..., -1.6221e+00,\n",
       "           -3.4221e-01, -3.2836e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[-1.0463,  1.8462,  1.9218,  ..., -3.1638,  2.8328, -1.9636],\n",
       "          [-0.4854,  1.4521,  3.6189,  ..., -3.2437,  2.0602, -0.6572],\n",
       "          [ 0.1325,  1.5088,  4.4767,  ..., -3.4909,  3.4174, -1.3850]],\n",
       "\n",
       "         [[-1.3271,  1.5119,  2.2108,  ...,  1.6477,  0.5076, -4.2283],\n",
       "          [-1.3286,  0.6128,  2.5852,  ...,  1.1492,  0.9771, -3.1138],\n",
       "          [-2.0233,  2.3604,  0.8829,  ...,  1.2308,  0.8524, -3.3119]],\n",
       "\n",
       "         [[-1.9914, -1.4289, -1.7475,  ...,  0.9258, -0.1095,  0.5448],\n",
       "          [-2.0277, -1.0849, -2.1611,  ..., -0.5309,  0.8111,  0.9299],\n",
       "          [-1.5188, -1.2883,  0.2439,  ..., -0.8023,  0.0523,  3.0309]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.1855, -0.3245, -0.1649,  ...,  0.2930, -0.3566, -0.8319],\n",
       "          [-0.9619,  0.9143,  0.6259,  ...,  1.0442, -0.5026, -1.3787],\n",
       "          [ 0.8694,  0.6022, -0.6294,  ...,  1.3564,  0.3122,  0.4711]],\n",
       "\n",
       "         [[ 0.0373,  0.3577,  1.2775,  ...,  0.8902,  0.0463,  0.6387],\n",
       "          [ 1.8376, -1.0313,  3.2904,  ...,  2.3437,  0.8767,  2.6376],\n",
       "          [ 1.0653, -0.6361,  5.3848,  ...,  2.4402,  1.0301,  2.2677]],\n",
       "\n",
       "         [[ 3.8089,  0.4320,  1.9079,  ..., -0.2018,  2.1208, -1.4855],\n",
       "          [ 1.6017,  0.9643,  1.0793,  ...,  0.1359,  2.6739, -2.2762],\n",
       "          [ 3.2914,  1.9252,  3.3933,  ..., -0.2130,  3.5423, -2.9113]]]],\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[ 4.0797e-01, -4.9203e-01, -5.5671e-01,  ..., -3.5725e-01,\n",
       "            1.1399e-01, -1.0397e-01],\n",
       "          [ 3.8853e-01,  1.0562e+00, -1.6170e-02,  ..., -9.7822e-02,\n",
       "           -6.4701e-01,  1.5508e-01],\n",
       "          [-5.9288e-01, -2.7546e-01,  1.0747e+00,  ..., -7.6221e-02,\n",
       "            3.6632e-01,  1.8958e+00]],\n",
       "\n",
       "         [[ 3.0818e-01, -6.0893e-02, -4.1910e-03,  ...,  1.4067e-01,\n",
       "            1.9035e-01,  3.5099e-01],\n",
       "          [ 4.7740e-02,  3.5933e-01,  4.6968e-01,  ..., -5.1009e-01,\n",
       "           -7.7374e-01,  1.5318e-01],\n",
       "          [-3.5023e-01, -2.4136e-02, -1.7003e-01,  ...,  5.4779e-01,\n",
       "            5.4928e-03,  1.4428e+00]],\n",
       "\n",
       "         [[-4.1982e-01, -2.4157e-01, -6.1193e-01,  ..., -1.8188e-01,\n",
       "            9.4194e-02, -1.2297e-01],\n",
       "          [ 1.7197e-01,  6.8403e-01, -4.5086e-01,  ...,  4.1388e-02,\n",
       "            1.1406e+00,  8.8747e-01],\n",
       "          [ 1.8474e+00, -4.8861e-01,  7.5388e-01,  ...,  4.6879e-01,\n",
       "            1.9479e-01,  1.4149e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.5342e-01,  2.3286e-02,  9.2370e-01,  ...,  1.2083e-01,\n",
       "            2.0489e-04,  2.0789e-03],\n",
       "          [-1.1339e-01,  9.7255e-01,  1.5540e+00,  ..., -3.0612e-01,\n",
       "           -3.6851e-01,  4.9200e-01],\n",
       "          [-5.5231e-01,  5.2209e-01, -2.4953e-01,  ...,  1.0992e+00,\n",
       "            1.0094e+00,  2.7235e-01]],\n",
       "\n",
       "         [[-4.4661e-01,  1.5172e-01,  1.4946e-02,  ...,  2.9086e-02,\n",
       "           -2.2025e-02,  2.5207e-01],\n",
       "          [ 9.6439e-01,  9.5407e-01,  6.7372e-01,  ...,  3.4384e-01,\n",
       "           -6.3510e-01, -3.6725e-02],\n",
       "          [ 1.0012e+00,  2.0466e-01, -4.6202e-01,  ..., -1.0402e+00,\n",
       "            3.9233e-01, -1.6270e-02]],\n",
       "\n",
       "         [[-2.0721e-01, -9.3749e-02,  2.4316e-02,  ..., -3.3098e-01,\n",
       "            2.2858e-02, -3.4502e-01],\n",
       "          [-3.9778e-01, -4.5411e-01, -1.3101e+00,  ..., -1.3599e+00,\n",
       "            1.1169e+00, -5.6354e-01],\n",
       "          [-2.6969e-01, -4.9715e-01, -8.4904e-01,  ..., -2.0412e-01,\n",
       "            1.7693e-01, -1.7669e+00]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[-1.7194e-01, -1.4547e+00,  9.8952e-01,  ...,  1.5594e-01,\n",
       "            1.1230e+00,  2.8778e+00],\n",
       "          [-2.8844e-01, -2.4745e+00,  2.3523e+00,  ...,  8.1623e-02,\n",
       "            1.8237e+00,  4.1673e+00],\n",
       "          [-3.3015e-01, -2.0311e+00,  1.7828e+00,  ..., -9.2284e-01,\n",
       "            1.1157e+00,  2.1877e+00]],\n",
       "\n",
       "         [[-1.3773e+00,  1.5374e+00,  6.6857e-01,  ..., -1.3388e+00,\n",
       "            2.7467e-01,  1.1591e+00],\n",
       "          [ 1.1955e-02,  1.7974e+00,  1.1003e+00,  ..., -3.5660e+00,\n",
       "            3.5570e-01,  2.3508e+00],\n",
       "          [-2.2691e-01,  1.5159e+00, -2.6009e-01,  ..., -3.0878e+00,\n",
       "            6.8825e-04,  2.2866e+00]],\n",
       "\n",
       "         [[-8.4965e-01, -5.5827e-01, -1.7880e-01,  ...,  4.4959e-01,\n",
       "           -1.2109e+00,  5.3867e-01],\n",
       "          [-4.0920e-01,  4.2497e-02,  2.2267e+00,  ...,  5.0681e-01,\n",
       "           -1.4293e+00, -9.0277e-01],\n",
       "          [-1.7140e+00, -2.9275e+00,  3.4913e+00,  ..., -8.7498e-02,\n",
       "           -1.0841e-01, -4.5431e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.1788e+00, -1.1404e-01, -5.6269e-01,  ...,  8.0836e-01,\n",
       "            4.1996e-01,  1.5122e+00],\n",
       "          [ 2.2327e+00,  4.7637e-01, -1.4330e+00,  ...,  1.8762e+00,\n",
       "            1.2365e+00,  3.0162e-01],\n",
       "          [ 1.9874e+00, -1.3316e+00, -2.1421e+00,  ...,  5.4536e-01,\n",
       "            4.0648e-01, -3.9765e-01]],\n",
       "\n",
       "         [[-2.2099e-01,  2.4317e+00,  3.1818e-01,  ...,  4.4831e-01,\n",
       "           -6.6353e-01, -1.1241e-02],\n",
       "          [ 2.7717e-01,  1.6940e-01,  6.1544e-01,  ..., -5.9591e-01,\n",
       "            1.5763e-01,  6.2293e-01],\n",
       "          [ 1.7799e+00,  1.3435e+00,  2.7713e-01,  ..., -1.2769e+00,\n",
       "           -1.8188e+00,  1.5334e+00]],\n",
       "\n",
       "         [[-5.9152e-01, -1.0195e+00,  3.3458e+00,  ...,  2.0412e+00,\n",
       "            7.0485e-01, -1.7908e+00],\n",
       "          [-1.5795e+00,  6.2600e-01,  2.1561e+00,  ...,  1.2270e+00,\n",
       "            2.4567e+00, -4.7651e+00],\n",
       "          [-4.9807e-01,  1.7413e+00,  1.6630e+00,  ...,  1.3388e+00,\n",
       "            2.1033e+00, -4.5404e+00]]]], grad_fn=<PermuteBackward0>), tensor([[[[ 0.5222,  0.6252, -0.3120,  ...,  0.1156, -0.2193,  0.5725],\n",
       "          [ 1.5216,  0.3341,  0.4708,  ..., -0.5301, -0.2737, -1.7634],\n",
       "          [ 1.6771, -0.2332, -0.1178,  ...,  0.3207,  0.6198, -1.0060]],\n",
       "\n",
       "         [[-0.1144, -0.2063, -0.2089,  ..., -0.3840,  0.1692,  0.2842],\n",
       "          [ 0.8566,  0.4619,  1.7087,  ...,  0.8610,  0.6761,  1.1517],\n",
       "          [-0.0915, -1.3510,  0.5216,  ...,  0.9406, -0.3288,  0.4962]],\n",
       "\n",
       "         [[ 0.3631, -0.2510,  0.3747,  ..., -0.1264, -0.3272, -0.0726],\n",
       "          [ 0.8664, -0.4079,  0.6529,  ..., -0.4893, -0.1082, -0.2328],\n",
       "          [ 0.2655, -0.7043,  0.7076,  ..., -0.7359,  0.0647,  1.0897]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.2394,  0.5176, -0.0432,  ..., -0.1300,  0.0881, -0.2572],\n",
       "          [-0.2101, -0.2516,  0.0297,  ..., -0.8515,  0.7431,  1.0955],\n",
       "          [-0.3782,  1.2171,  0.3944,  ..., -0.6645,  0.4972,  0.2464]],\n",
       "\n",
       "         [[-0.7838,  0.4835,  0.0604,  ...,  0.7297, -0.3713,  0.3072],\n",
       "          [ 0.0900, -0.6804, -1.1660,  ..., -0.0332,  3.4917,  1.3134],\n",
       "          [ 0.4958,  0.8671, -0.5183,  ..., -0.9441,  2.5999,  0.5224]],\n",
       "\n",
       "         [[ 0.2340,  0.2038,  0.3648,  ...,  0.1451, -0.2014,  0.5321],\n",
       "          [-0.8059,  0.8669, -0.1502,  ...,  1.6738,  0.6719, -0.8701],\n",
       "          [ 0.0898,  0.0186, -0.5267,  ..., -0.4183,  0.4886,  0.2381]]]],\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[ 0.4342, -0.3588,  0.4980,  ..., -1.3603, -2.2850,  1.4753],\n",
       "          [ 1.2045, -0.1570,  0.1574,  ..., -0.7359, -2.1429,  1.1196],\n",
       "          [ 1.1114, -2.8888,  1.3726,  ..., -1.8982, -1.7452,  2.4469]],\n",
       "\n",
       "         [[-0.9664, -1.3589,  0.6389,  ..., -1.4890, -0.4478, -1.3979],\n",
       "          [ 0.2169, -1.1962,  0.4887,  ..., -1.3325, -0.4882, -0.5870],\n",
       "          [-0.5439, -0.8727,  0.6981,  ..., -1.1284, -2.0441, -2.3389]],\n",
       "\n",
       "         [[ 0.4456,  0.7835, -0.7423,  ..., -1.7426,  0.9995,  0.1752],\n",
       "          [ 0.2106,  1.6415, -1.1851,  ..., -1.7540,  2.0100, -0.2913],\n",
       "          [-1.0609,  0.6523, -1.7407,  ..., -3.1234,  1.0857, -1.6687]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.1109, -0.0501,  2.0751,  ...,  0.1612,  1.8325,  2.4627],\n",
       "          [ 1.3810,  0.3658,  2.7817,  ..., -0.2523,  1.9738,  3.1686],\n",
       "          [ 1.1329,  1.0142,  3.1425,  ..., -0.8701,  2.5383,  0.5004]],\n",
       "\n",
       "         [[-0.8276, -2.4916, -0.6884,  ..., -2.1446,  3.1232,  0.9054],\n",
       "          [-2.1415, -1.9373, -0.4734,  ..., -3.1323,  2.4304, -1.2514],\n",
       "          [-3.8738, -1.1731, -3.1110,  ..., -1.4171,  2.2916, -1.2801]],\n",
       "\n",
       "         [[-0.7413, -0.1360, -0.1298,  ..., -0.1754,  0.1302, -1.1956],\n",
       "          [-1.5731, -0.2284, -0.7739,  ..., -0.3631,  1.9446, -0.9162],\n",
       "          [-0.8141,  1.7915,  0.3389,  ..., -0.9167, -0.4970, -0.3836]]]],\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[ 9.8894e-02, -2.6306e-01,  5.7063e-01,  ..., -4.3800e-01,\n",
       "            4.1572e-01,  1.5574e-01],\n",
       "          [-1.8618e+00, -5.4286e-02,  5.1287e-01,  ..., -1.0074e+00,\n",
       "           -2.0593e-01, -1.3550e+00],\n",
       "          [-2.1585e-02, -6.1367e-01,  9.4903e-02,  ..., -1.4448e+00,\n",
       "            5.2892e-01, -1.0057e+00]],\n",
       "\n",
       "         [[ 2.2431e-01, -1.7319e-02, -1.1877e-01,  ..., -2.8742e-01,\n",
       "           -8.2855e-02, -4.3882e-01],\n",
       "          [ 3.3510e-01,  2.6464e-01,  3.4535e-01,  ...,  1.2236e+00,\n",
       "            3.4343e-01, -3.4227e-01],\n",
       "          [-7.5166e-01,  1.0144e+00, -2.2737e-01,  ...,  8.3510e-01,\n",
       "            1.0028e-01, -5.7814e-01]],\n",
       "\n",
       "         [[ 6.8968e-02, -4.6436e-01,  4.7274e-01,  ..., -1.7039e-01,\n",
       "           -4.7016e-01, -2.7617e-01],\n",
       "          [-8.7849e-01,  7.3355e-01,  1.0206e+00,  ...,  2.8681e-01,\n",
       "            2.1818e-01, -1.6575e-01],\n",
       "          [-9.2146e-01,  9.3515e-02,  1.0859e+00,  ..., -1.0911e+00,\n",
       "            5.8571e-01,  5.0734e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.6965e-01, -1.0830e-03, -5.7500e-02,  ...,  1.6371e-01,\n",
       "           -1.3577e-01,  1.2394e-01],\n",
       "          [ 2.3018e+00,  1.9471e-01,  1.0197e+00,  ..., -5.2449e-01,\n",
       "            3.8317e-01,  7.8098e-01],\n",
       "          [ 2.4654e-01,  7.1541e-01,  1.6264e+00,  ..., -1.3628e+00,\n",
       "            2.7577e-01,  1.4936e-01]],\n",
       "\n",
       "         [[ 1.4518e-01, -1.4102e-01, -1.6602e-01,  ..., -2.3945e-02,\n",
       "            1.5399e-01, -1.7259e-01],\n",
       "          [ 4.0667e-01, -1.3886e-01, -3.1489e-01,  ...,  4.9855e-01,\n",
       "            1.1776e+00, -2.3455e-01],\n",
       "          [-5.2377e-01,  3.3473e-01, -9.8548e-02,  ...,  8.5228e-01,\n",
       "            1.0439e-01,  6.9472e-01]],\n",
       "\n",
       "         [[ 7.6431e-01,  2.6154e-01,  2.9742e-01,  ..., -3.3901e-01,\n",
       "           -8.9064e-01, -1.6354e-01],\n",
       "          [ 2.4590e-01,  9.0431e-02, -2.6673e-01,  ...,  4.9080e-01,\n",
       "           -1.0592e+00, -1.1490e+00],\n",
       "          [-8.3091e-02,  1.5953e-01,  1.9158e-01,  ...,  5.0917e-01,\n",
       "            2.8639e-01, -4.7582e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[ 3.1930,  0.1081, -0.1053,  ..., -0.0917,  0.6530, -2.1737],\n",
       "          [ 3.0471,  0.5345,  0.9778,  ...,  1.4868,  1.2531, -3.6376],\n",
       "          [ 2.5235,  2.3518,  1.1639,  ...,  0.1713, -0.1551, -1.5542]],\n",
       "\n",
       "         [[ 0.0618, -1.1892, -0.6285,  ...,  1.0251, -1.2301,  1.7139],\n",
       "          [-1.0680,  0.3139,  0.2452,  ...,  1.1300,  0.6860,  0.8442],\n",
       "          [ 0.1843, -0.8544, -1.0789,  ...,  0.6483, -0.5974, -0.3888]],\n",
       "\n",
       "         [[-0.2571, -1.7783, -0.5575,  ..., -0.1537, -0.7493,  2.1307],\n",
       "          [-1.3578, -1.8706,  0.9051,  ..., -0.3970, -1.4546, -0.7500],\n",
       "          [-1.6862,  0.0957,  1.9666,  ..., -1.0210, -1.8261, -0.0570]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.0359,  0.0729,  1.3463,  ...,  1.8320, -1.4733,  1.3695],\n",
       "          [-1.3698, -0.5976,  0.7414,  ...,  1.9766, -2.6564,  1.5644],\n",
       "          [-1.3254,  0.3294,  0.9486,  ...,  1.0190, -1.9674,  1.4829]],\n",
       "\n",
       "         [[-0.8219, -0.6818, -0.8961,  ..., -0.6050, -0.1159,  0.0491],\n",
       "          [-0.6944,  0.1097, -1.4358,  ..., -1.7257, -0.1121, -0.6675],\n",
       "          [-0.0330, -0.5680, -1.0176,  ..., -1.0436,  0.0743, -0.6245]],\n",
       "\n",
       "         [[ 1.1295, -0.4073, -0.2529,  ..., -2.0204,  0.6150,  0.2084],\n",
       "          [ 0.2207, -1.7087,  1.0913,  ..., -0.7528,  0.5932,  1.0787],\n",
       "          [ 1.5438, -2.0306,  0.1068,  ..., -1.3919,  1.1213,  0.3816]]]],\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[-0.2981,  0.8472, -0.1083,  ...,  0.8523,  0.1104, -0.4116],\n",
       "          [ 0.6149,  0.3614, -0.5133,  ...,  0.0973,  0.9228, -0.9853],\n",
       "          [ 0.3354,  0.2120, -0.3782,  ...,  0.2662,  0.0883, -0.8174]],\n",
       "\n",
       "         [[ 0.6127, -0.9054,  0.4103,  ...,  0.0878, -0.2165,  0.2787],\n",
       "          [ 2.4250,  2.1042, -0.5015,  ...,  0.5880, -0.1628,  0.8073],\n",
       "          [-0.2433,  0.6180, -0.4065,  ...,  0.6531,  0.5888, -0.8410]],\n",
       "\n",
       "         [[ 0.0431, -0.3089,  0.7541,  ..., -0.0246, -0.3987, -0.3086],\n",
       "          [-0.3561, -0.7845,  0.3286,  ...,  1.0157, -1.2095, -0.2360],\n",
       "          [-0.3224, -0.3125, -0.1862,  ...,  1.5477, -1.9524, -0.2310]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0906, -0.4190,  0.4500,  ...,  0.0305,  0.2091,  0.4063],\n",
       "          [-0.3715, -0.7660, -0.8343,  ...,  0.7311, -0.5694, -0.4461],\n",
       "          [ 1.5107,  0.4654, -1.3544,  ...,  0.9530,  0.1686, -0.4799]],\n",
       "\n",
       "         [[-0.0049,  1.3635,  0.0757,  ..., -0.3538, -0.5847,  0.3770],\n",
       "          [-0.1254,  0.8943, -0.4830,  ...,  0.6314,  0.6773,  0.6864],\n",
       "          [ 0.1347, -0.4798, -0.0311,  ...,  0.5015,  0.2719, -0.8928]],\n",
       "\n",
       "         [[ 0.2883, -0.3424, -0.2740,  ...,  0.5260,  0.2014, -0.5343],\n",
       "          [ 0.6393,  0.6723, -0.5835,  ..., -0.6625, -0.1297,  0.0767],\n",
       "          [ 1.0383,  0.1391,  0.2478,  ...,  0.2294,  0.2607, -0.2188]]]],\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[-0.1416, -1.8069,  0.0872,  ..., -1.1959,  0.2646, -0.1036],\n",
       "          [-0.0587, -0.7229, -0.7833,  ..., -0.6983, -0.1222, -0.7886],\n",
       "          [-0.6119,  0.1181, -0.8138,  ...,  0.2324,  0.1582,  1.4602]],\n",
       "\n",
       "         [[ 0.0923,  0.8406,  0.1521,  ...,  1.3313, -0.3560, -1.0950],\n",
       "          [-0.8559,  0.1823, -2.1865,  ...,  2.0095, -0.4551, -0.3440],\n",
       "          [-0.7541, -1.4535, -1.3250,  ...,  2.2692,  0.2377, -0.9754]],\n",
       "\n",
       "         [[ 0.6171,  1.4588,  0.0898,  ..., -0.7124,  0.8851, -0.7680],\n",
       "          [ 0.7571,  1.8512, -0.1168,  ...,  0.1007,  1.9500,  0.0578],\n",
       "          [ 0.0625, -0.0266, -0.4420,  ...,  0.2241,  1.0621, -0.2564]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.1039, -0.1808, -0.9541,  ...,  0.0306,  0.0345, -1.8795],\n",
       "          [-0.2806, -1.1243, -2.1216,  ..., -0.6806, -1.0142, -0.1992],\n",
       "          [ 2.9539, -1.2279, -1.2694,  ...,  2.3675, -0.8806, -0.4676]],\n",
       "\n",
       "         [[ 0.2646, -0.0311,  1.5127,  ..., -0.0310, -0.3140,  0.3228],\n",
       "          [-0.0935,  0.3661,  0.8666,  ...,  1.5357, -0.3765,  0.0231],\n",
       "          [-0.9779,  1.0008,  1.1970,  ...,  1.7896, -0.5874,  1.0516]],\n",
       "\n",
       "         [[-1.0135,  0.0566,  0.9374,  ...,  0.5474,  0.5780,  0.0845],\n",
       "          [ 1.4233, -0.1106,  1.1472,  ...,  0.2259, -0.6041, -1.5779],\n",
       "          [ 1.6985, -0.9609,  0.0173,  ..., -0.2740,  1.4477, -1.6980]]]],\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[-0.2602,  0.3330, -0.3916,  ..., -0.5512, -0.4106,  0.1446],\n",
       "          [ 0.0621,  0.5871, -1.2274,  ...,  1.6698, -0.5067,  0.8338],\n",
       "          [ 1.0989,  1.9192, -1.7737,  ..., -0.5211,  1.0982, -0.7840]],\n",
       "\n",
       "         [[ 0.2193,  0.3767, -0.3644,  ...,  0.4335,  0.2262, -0.1285],\n",
       "          [ 0.8299,  0.6846,  0.6954,  ...,  0.1339,  0.1179, -0.1501],\n",
       "          [ 0.0062,  0.5843, -0.8717,  ...,  0.7702,  0.4366, -0.1555]],\n",
       "\n",
       "         [[-0.2703, -0.4146,  0.0071,  ...,  0.8966,  0.9536,  0.0945],\n",
       "          [ 0.8015, -0.0358, -0.1018,  ...,  0.2242,  1.0003, -1.2457],\n",
       "          [-0.5816,  0.1623, -0.2952,  ..., -0.0633,  0.4846,  0.6271]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0968,  0.2791, -0.5020,  ...,  0.5821,  0.0670,  0.7152],\n",
       "          [ 1.7987, -0.4363,  0.2023,  ...,  0.5368,  1.6773, -0.7176],\n",
       "          [ 0.8870, -0.6736, -0.4387,  ...,  0.4198,  1.0399, -0.4278]],\n",
       "\n",
       "         [[ 0.0422,  0.4457,  0.0592,  ...,  0.4753,  0.0093,  0.3499],\n",
       "          [-0.7725, -0.6354,  0.7212,  ..., -1.3027, -0.0572,  0.3223],\n",
       "          [ 0.2607,  0.0275,  0.5448,  ..., -1.0229,  0.2627, -0.1740]],\n",
       "\n",
       "         [[ 0.4463, -0.6335,  0.1888,  ...,  0.0185, -0.2234, -0.3475],\n",
       "          [-0.8061,  0.8688, -0.9209,  ...,  0.3186,  0.0158,  0.3579],\n",
       "          [ 0.2821,  0.2482, -0.1936,  ...,  0.8906, -0.2712, -0.4868]]]],\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[ 1.3344,  1.6407, -1.1168,  ..., -0.1853,  0.7437,  1.3448],\n",
       "          [ 0.4486,  2.1083,  0.0855,  ..., -0.3530,  0.7782,  2.5243],\n",
       "          [ 1.6168,  2.0437, -0.7914,  ..., -1.3453,  1.6296,  1.9632]],\n",
       "\n",
       "         [[ 1.7921, -0.0862,  0.0214,  ...,  0.8519, -1.4762,  0.7213],\n",
       "          [ 1.0824, -0.2517, -0.5896,  ..., -0.8241, -2.1220,  0.4892],\n",
       "          [ 1.0178, -0.2300, -0.8001,  ...,  0.4928, -1.4391, -0.1368]],\n",
       "\n",
       "         [[-0.3435,  1.2281, -0.4626,  ...,  1.9057, -1.2092, -1.3509],\n",
       "          [-0.2746,  0.5046, -1.6655,  ...,  0.5347,  0.4660, -0.6501],\n",
       "          [-1.5525,  0.2291, -2.3367,  ..., -1.0252, -0.5658, -1.8525]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.3387,  0.3783, -0.3107,  ..., -0.0031, -0.6504,  0.7345],\n",
       "          [-0.2419,  1.3442, -0.9397,  ...,  0.1332, -1.4448,  0.0694],\n",
       "          [-1.1557,  0.9253, -0.8686,  ..., -0.0670, -1.3109, -0.1649]],\n",
       "\n",
       "         [[ 2.8156, -1.2239, -0.1549,  ..., -0.5170, -0.4739,  1.2636],\n",
       "          [ 1.1088, -0.1337, -0.3854,  ..., -1.3909, -0.4896,  0.8264],\n",
       "          [ 1.2264,  0.4188, -2.2671,  ..., -0.8469, -1.0412,  1.0915]],\n",
       "\n",
       "         [[-0.5628,  0.7549,  0.1146,  ..., -1.5425,  1.0270,  1.3423],\n",
       "          [-0.1010,  0.3311, -0.1985,  ..., -0.4391, -0.3789, -0.3746],\n",
       "          [ 1.8370, -1.0544,  0.4384,  ..., -2.6290, -0.4352, -1.6875]]]],\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[-6.5516e-02,  5.6238e-01,  1.7743e-03,  ...,  1.1579e-01,\n",
       "            7.8892e-01, -1.7030e-01],\n",
       "          [-1.1390e+00,  9.0418e-01, -1.9700e-01,  ...,  2.8184e-01,\n",
       "            8.6300e-01, -2.6001e-02],\n",
       "          [-4.1019e-01,  4.6742e-03,  6.1136e-01,  ...,  2.0889e+00,\n",
       "            2.7651e-02, -1.5289e+00]],\n",
       "\n",
       "         [[-1.6612e-01,  1.6033e-01,  1.8774e-02,  ..., -2.1932e-01,\n",
       "            7.1894e-01,  7.5041e-02],\n",
       "          [-1.5446e+00, -3.8144e-01,  1.4748e-01,  ...,  3.6298e-01,\n",
       "           -3.6060e-01,  1.0114e+00],\n",
       "          [ 1.5124e+00, -2.1443e-01, -3.5328e-04,  ..., -5.6592e-01,\n",
       "           -7.1284e-01, -4.2646e-01]],\n",
       "\n",
       "         [[-6.8413e-01,  3.5747e-01, -4.1315e-01,  ..., -1.1915e+00,\n",
       "            1.2308e+00,  1.1208e+00],\n",
       "          [ 6.2896e-02, -2.8266e-01,  1.9440e-01,  ..., -3.3238e-01,\n",
       "            3.8268e-01,  1.7801e-02],\n",
       "          [-6.8714e-01, -1.8828e+00, -4.4192e-01,  ..., -6.1976e-01,\n",
       "            8.3003e-01,  1.5374e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 5.0889e-01, -5.9860e-01,  2.1137e-02,  ...,  1.1603e-01,\n",
       "           -9.1386e-01,  5.8713e-01],\n",
       "          [-5.6806e-02,  1.7683e-02,  5.8953e-01,  ..., -3.1237e-01,\n",
       "            1.5692e-01,  5.1995e-01],\n",
       "          [ 2.0727e-01, -4.9599e-02, -2.1905e-01,  ..., -1.4561e+00,\n",
       "            5.7842e-01,  4.9615e-01]],\n",
       "\n",
       "         [[ 1.2403e-01, -1.0252e+00,  2.9894e-01,  ...,  5.9098e-02,\n",
       "            1.3221e-01, -6.5238e-01],\n",
       "          [-2.3404e-01, -9.3423e-01,  3.1233e-02,  ..., -1.2204e-01,\n",
       "           -3.6483e-02,  2.0828e-01],\n",
       "          [ 2.1647e-01, -2.6582e-01, -3.3905e-01,  ...,  8.5153e-01,\n",
       "           -9.7132e-01, -4.9120e-01]],\n",
       "\n",
       "         [[-3.4276e-01, -1.1631e-02, -1.4642e+00,  ...,  3.7392e-02,\n",
       "            1.2321e+00, -3.2502e-01],\n",
       "          [ 1.2135e-01, -1.0021e+00,  7.9992e-01,  ...,  2.4446e-01,\n",
       "            6.3208e-01, -6.0150e-02],\n",
       "          [ 6.9210e-01, -4.0448e-01, -2.9661e-01,  ...,  1.5371e-01,\n",
       "           -1.3268e-01, -7.9411e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[ 0.0346,  0.6191, -0.5131,  ..., -0.3087,  1.3462, -2.5713],\n",
       "          [ 1.4901,  0.0959,  0.8511,  ..., -0.0696,  1.0663, -1.5698],\n",
       "          [ 1.6020, -0.0957,  1.0231,  ...,  1.5630,  1.1925, -1.4073]],\n",
       "\n",
       "         [[-1.2521, -2.4782,  0.8420,  ..., -0.1494,  1.8119, -0.9250],\n",
       "          [ 1.2691, -2.2572,  1.0193,  ...,  0.1710,  0.9855, -0.2816],\n",
       "          [ 0.4046, -1.4194,  1.1129,  ...,  0.0644,  0.4758, -0.4508]],\n",
       "\n",
       "         [[-0.0082, -0.2073,  0.0391,  ..., -0.5936, -0.4180, -0.7864],\n",
       "          [-2.3547, -1.5457, -1.3856,  ..., -1.7286,  0.5390, -1.1913],\n",
       "          [-0.9426,  1.4356, -0.8591,  ..., -0.8671, -0.1935,  0.5688]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.8284, -0.8852, -1.4832,  ..., -1.0977,  0.5395,  0.6642],\n",
       "          [ 1.0947, -0.1375, -0.4741,  ...,  0.0776,  0.3984,  2.0398],\n",
       "          [ 1.2284,  1.0676, -1.6271,  ..., -1.3671,  0.1731,  1.5147]],\n",
       "\n",
       "         [[ 0.5815, -0.6931, -0.0692,  ..., -0.7073,  0.5564, -0.8789],\n",
       "          [-1.2626,  0.2047, -1.1367,  ..., -1.4401, -1.0038, -0.3460],\n",
       "          [-2.3618, -0.0988,  0.6446,  ..., -2.1422, -0.6543, -1.6118]],\n",
       "\n",
       "         [[ 0.4400, -1.1342,  0.2408,  ..., -0.2345, -1.4742, -0.3241],\n",
       "          [ 0.8957, -2.1311,  2.3429,  ...,  0.9661, -2.3738, -0.2610],\n",
       "          [ 0.0802, -1.9071,  0.5826,  ...,  1.1405, -1.2886,  0.2563]]]],\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[ 6.2530e-01,  6.3414e-01, -6.3294e-01,  ..., -5.9172e-01,\n",
       "           -1.0798e+00,  1.5442e+00],\n",
       "          [ 3.6615e-01, -4.8065e-01,  1.7405e-01,  ..., -6.1528e-01,\n",
       "           -9.2192e-01, -7.4092e-01],\n",
       "          [ 1.3225e+00,  1.3198e-01, -2.9035e-01,  ..., -1.0106e+00,\n",
       "           -4.7664e-01, -1.0150e+00]],\n",
       "\n",
       "         [[ 3.0180e-01, -3.5841e-01, -9.6130e-01,  ..., -7.8911e-01,\n",
       "            1.1986e-01, -4.4198e-02],\n",
       "          [-3.1575e-01, -4.4014e-01, -1.7668e-01,  ..., -7.0647e-01,\n",
       "            7.2559e-01, -4.4950e-01],\n",
       "          [-4.8449e-01,  3.3092e-01, -8.0679e-01,  ...,  1.0420e+00,\n",
       "            6.0653e-01, -1.2728e+00]],\n",
       "\n",
       "         [[-8.2458e-01,  3.2570e-01,  1.2734e+00,  ..., -6.4802e-01,\n",
       "            3.2082e-02,  8.3302e-02],\n",
       "          [ 6.5147e-01,  4.7906e-02,  1.8396e+00,  ..., -3.0832e-01,\n",
       "           -4.8226e-01, -2.1921e-01],\n",
       "          [ 1.6349e-03,  4.2522e-01,  7.2539e-01,  ..., -4.0639e-01,\n",
       "            1.6688e-01,  8.6832e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-5.6588e-01,  2.3102e-01, -4.0427e-02,  ..., -6.7021e-02,\n",
       "           -3.8406e-01, -7.1567e-01],\n",
       "          [-2.1983e+00,  1.2651e+00,  6.4385e-02,  ...,  4.0741e-01,\n",
       "           -6.5669e-01,  1.1187e+00],\n",
       "          [-1.0898e+00,  1.7457e+00,  9.2802e-01,  ...,  2.7395e-01,\n",
       "           -4.7698e-01,  9.9486e-01]],\n",
       "\n",
       "         [[-6.8134e-03, -2.6101e-01,  1.0728e+00,  ..., -3.7906e-01,\n",
       "           -3.4710e-01,  1.0443e+00],\n",
       "          [ 9.8450e-01, -4.6757e-01,  3.5113e-01,  ..., -1.1004e+00,\n",
       "           -4.1979e-01, -5.6376e-01],\n",
       "          [ 4.4070e-01,  3.6394e-02, -5.4046e-01,  ..., -9.4961e-01,\n",
       "           -1.5785e-01, -1.4744e-01]],\n",
       "\n",
       "         [[-1.2769e+00, -4.2746e-01, -1.5310e-01,  ..., -1.0344e+00,\n",
       "            4.4327e-01, -4.1985e-01],\n",
       "          [-6.0867e-01, -1.0038e+00, -4.5462e-01,  ...,  4.4037e-01,\n",
       "            1.3076e+00, -1.3374e+00],\n",
       "          [-1.2120e+00, -2.4639e-01, -5.1062e-01,  ...,  1.5560e+00,\n",
       "            6.1226e-01, -3.7035e-01]]]], grad_fn=<PermuteBackward0>))), hidden_states=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text-generation-poem-petofi-gpt2-small-hungarian\n",
    "# Run time: 21m\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"NYTK/text-generation-poem-petofi-gpt2-small-hungarian\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"NYTK/text-generation-poem-petofi-gpt2-small-hungarian\")\n",
    "\n",
    "get_avg_res(tokenizer,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at SZTAKI-HLT/hubert-base-cc were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9959319631118843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.7243,  0.1612,  1.0162,  ...,  0.0296, -1.0394, -0.6103],\n",
       "         [ 0.1038,  0.0367, -0.2054,  ..., -0.3088, -0.2042,  0.0630],\n",
       "         [-0.0236, -0.0078, -0.1343,  ..., -0.1722, -0.2199,  0.1102],\n",
       "         [ 0.1544,  0.3130,  0.2988,  ...,  0.1123, -0.1340, -0.0057],\n",
       "         [ 0.1782, -0.0350,  0.2302,  ...,  0.0378, -0.0184,  0.1245]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.2092,  0.8206,  0.6497, -0.8355,  0.1763,  0.8134,  0.6644, -0.8871,\n",
       "          0.8742, -0.7669, -0.6076,  0.1038, -0.9331,  0.9627,  0.7116,  0.3723,\n",
       "          0.9161, -0.9955, -0.6619, -0.4602,  0.8201, -0.7894, -0.3004,  0.5493,\n",
       "         -0.9972, -0.7139,  0.5849,  0.7389,  0.9486, -0.3229, -0.6968, -0.7561,\n",
       "          0.7681,  0.5077, -0.6867, -0.7087, -0.8041, -0.2222,  0.0110,  0.9801,\n",
       "         -0.9728, -0.6081, -0.7769,  0.6002, -0.7114,  0.6427, -0.7834, -0.7847,\n",
       "         -0.7656,  0.3371, -0.5005, -0.9582,  0.4824,  0.7267, -0.5786, -0.6364,\n",
       "          0.5973,  0.9311,  0.4539,  0.7635, -0.9557, -0.7067,  0.7715, -0.3567,\n",
       "         -0.7320, -0.6744,  0.9651, -0.8689, -0.4686, -0.6978, -0.3106,  0.8176,\n",
       "         -0.2419,  0.8057, -0.8562, -0.9207, -0.8109,  0.7488,  0.6767,  0.7448,\n",
       "          0.7380,  0.7729, -0.9810, -0.9367,  0.7732, -0.7913, -0.9989,  0.3835,\n",
       "         -0.6320,  0.9098,  0.8305,  0.9188, -0.6782, -0.5991,  0.6297, -0.9412,\n",
       "         -0.0683,  0.7827, -0.5412, -0.6852, -0.0861, -0.9678, -0.4903,  0.6778,\n",
       "         -0.0318,  0.9678,  0.7523, -0.9938, -0.8547, -0.5605,  0.9945,  0.9193,\n",
       "         -0.9256,  0.9727, -0.9085, -0.4717,  0.8300, -0.1896,  0.7293, -0.1306,\n",
       "          0.7656,  0.9772, -0.1324,  0.8163, -0.6845,  0.9652,  0.6919,  0.6946,\n",
       "         -0.6746,  0.1345,  0.7180, -0.7596,  0.9088, -0.9607,  0.6801, -0.9403,\n",
       "         -0.1666,  0.9366, -0.8557, -0.9717,  0.6230,  0.6064,  0.6845,  0.1884,\n",
       "          0.7162,  0.8207, -0.4259, -0.2921,  0.6851, -0.5984,  0.8837, -0.7164,\n",
       "         -0.7112,  0.7677,  0.7479, -0.8997,  0.6181,  0.1865,  0.5705, -0.7442,\n",
       "         -0.7303, -0.5939, -0.9937,  0.5965,  0.7099,  0.7180,  0.5154,  0.8299,\n",
       "          0.6817, -0.8052, -0.7395,  0.0220, -0.6634,  0.5822, -0.8441, -0.7545,\n",
       "          0.7991, -0.7472,  0.7033, -0.7357,  0.8288,  0.0012, -0.6632,  0.4479,\n",
       "          0.1235, -0.8294,  0.6456,  0.5871, -0.5306,  0.8347, -0.9514,  0.7083,\n",
       "          0.6884,  0.6341, -0.6953,  0.8130, -0.9509, -0.6608, -0.0718,  0.4194,\n",
       "          0.7286,  0.8927,  0.6038,  0.1256, -0.5299, -0.6181, -0.9640,  0.0478,\n",
       "         -0.6418,  0.0398,  0.9124,  0.5847,  0.4690, -0.8840,  0.2537, -0.1184,\n",
       "         -0.0140,  0.7368, -0.1769, -0.9890,  0.8899, -0.0752, -0.8177, -0.1022,\n",
       "          0.4202, -0.6749, -0.7277, -0.7908, -0.4113,  0.5073,  0.7801, -0.3887,\n",
       "          0.7589, -0.1890,  0.5616,  0.9995,  0.8648,  0.9719, -0.5409, -0.2240,\n",
       "         -0.6989,  0.1994,  0.8932,  0.5839,  0.9396, -0.7615, -0.7333, -0.7250,\n",
       "          0.5503, -0.8435, -0.9608, -0.9762, -0.7540, -0.7932, -0.7128,  0.7989,\n",
       "         -0.4727, -0.2428,  0.6661,  0.3657, -0.6568,  0.7952, -0.9607, -0.8654,\n",
       "          0.8962,  0.7136,  0.9732, -0.9991, -0.8385,  0.1862, -0.3443,  0.8037,\n",
       "          0.6434, -0.8590, -0.7841,  0.9147, -0.5793,  0.1612,  0.6466, -0.6158,\n",
       "          0.9079,  0.8836,  0.9777,  0.8024, -0.6381, -0.6344,  0.9877, -0.8360,\n",
       "          0.7702,  0.1891,  0.7011,  0.8068, -0.7357,  0.5307,  0.7513, -0.9552,\n",
       "         -0.9522,  0.5745,  0.6547, -0.8875, -0.4880,  0.6451, -0.7166,  0.2547,\n",
       "         -0.8448,  0.9185,  0.9033,  0.5230,  0.9752,  0.8985, -0.7501,  0.7013,\n",
       "         -0.6263,  0.7274, -0.7081, -0.6094, -0.8580,  0.8707, -0.7868,  0.6542,\n",
       "         -0.7478,  0.6285,  0.2968, -0.1923, -0.8503, -0.9713,  0.3141,  0.0368,\n",
       "         -0.5125,  0.9225,  0.4951, -0.0298,  0.6803, -0.6962, -0.8000,  0.7531,\n",
       "          0.2944, -0.9023,  0.9173, -0.9000, -0.8620, -0.7097,  0.8777,  0.9312,\n",
       "          0.7310,  0.9090,  0.7259,  0.6951, -0.5712,  0.7724,  0.6395, -0.6231,\n",
       "         -0.8095, -0.6568, -0.9988, -0.6805,  0.9288,  0.6200,  0.7380,  0.3961,\n",
       "         -0.1681, -0.8626, -0.9355,  0.5811,  0.8735,  0.6917,  0.0710,  0.6912,\n",
       "         -0.7617,  0.9706, -0.4030,  0.9063,  0.9160, -0.3678,  0.8065, -0.9992,\n",
       "         -0.5956,  0.8936, -0.1276, -0.7137, -0.2442, -0.7098, -0.7253, -0.4289,\n",
       "          0.9953,  0.7612,  0.9531, -0.8715, -0.9786, -0.6951, -0.7701,  0.6167,\n",
       "          0.7520, -0.9940, -0.9838, -0.9925, -0.5563, -0.5506, -0.7214,  0.5993,\n",
       "         -0.7508,  0.9764, -0.8377, -0.3448, -0.9728, -0.4459, -0.9187, -0.7105,\n",
       "          0.8695,  0.8004, -0.9612, -0.7014, -0.1636, -0.5187,  0.6477, -0.5852,\n",
       "         -0.6904, -0.7158,  0.3344, -0.9502, -0.3622, -0.8157, -0.8859,  0.6324,\n",
       "          0.7444, -0.5002, -0.6515, -0.9096, -0.7011,  0.6962,  0.2740,  0.6824,\n",
       "          0.6201,  0.4332,  0.7791, -0.8184,  0.9547, -0.6760, -0.9863, -0.8618,\n",
       "         -0.4058,  0.8349,  0.7858,  0.8619,  0.7123, -0.7926,  0.6676, -0.9724,\n",
       "          0.8022,  0.9560,  0.8901, -0.6976,  0.8715,  0.8380, -0.7596, -0.7216,\n",
       "         -0.8043, -0.2453, -0.7137,  0.9154, -0.7513, -0.7221, -0.9682,  0.4325,\n",
       "         -0.7744, -0.9891,  0.1468,  0.3603,  0.7627,  0.6731, -0.6761,  0.9122,\n",
       "         -0.6915, -0.8060, -0.6151, -0.3945,  0.4036, -0.8761, -0.9734,  0.8820,\n",
       "          0.6381,  0.6213,  0.9727,  0.1687, -0.9699,  0.7039,  0.8982,  0.7162,\n",
       "         -0.6141,  0.8906,  0.7896, -0.9765, -0.3460, -0.2767, -0.9297,  0.8200,\n",
       "          0.6310, -0.6678, -0.7121,  0.5959, -0.6950,  0.6725, -0.7500, -0.0699,\n",
       "         -0.6641, -0.6938,  0.7898, -0.7178,  0.3388,  0.9530, -0.2264,  0.6867,\n",
       "          0.7352,  0.5496,  0.4150, -0.5901, -0.8291, -0.7823,  0.8127, -0.6056,\n",
       "         -0.7164, -0.9547, -0.7846,  0.0057,  0.7706, -0.9481,  0.9524,  0.7942,\n",
       "          0.7485, -0.8135, -0.7927,  0.4019, -0.6620,  0.8401,  0.8149,  0.8401,\n",
       "         -0.0997, -0.1696, -0.5812, -0.6206,  0.4130, -0.8830, -0.4963, -0.5866,\n",
       "          0.0305, -0.6505,  0.7470, -0.9317,  0.7860,  0.7785, -0.3016, -0.6588,\n",
       "         -0.7048, -0.6877, -0.9330, -0.1744,  0.9325, -0.0968, -0.7895,  0.9083,\n",
       "          0.9093,  0.6559,  0.7638,  0.6049, -0.7019,  0.6981, -0.6902,  0.9635,\n",
       "          0.3370, -0.9131, -0.2125, -0.7844,  0.9614,  0.6014,  0.7156,  0.9226,\n",
       "         -0.9237,  0.7683,  0.0901, -0.7775, -0.0274, -0.6360,  0.5896,  0.6004,\n",
       "         -0.7534, -0.9760, -0.9951, -0.8579, -0.8017,  0.8110, -0.6929, -0.4939,\n",
       "          0.9836,  0.7737, -0.8916, -0.8702, -0.8923,  0.1528, -0.6423,  0.2331,\n",
       "          0.0637, -0.8985,  0.7029,  0.7794, -0.6899,  0.6738,  0.6565, -0.9230,\n",
       "          0.8550, -0.6181, -0.6997,  0.7487,  0.9306,  0.8218, -0.6593,  0.8217,\n",
       "          0.9964, -0.6797, -0.7400, -0.2656, -0.6309, -0.3307, -0.7277, -0.0590,\n",
       "         -0.9745, -0.5831,  0.7788, -0.9229, -0.8202,  0.8597,  0.8803, -0.6319,\n",
       "         -0.6814, -0.6671,  0.2356, -0.5182, -0.8208,  0.2949,  0.8171,  0.8991,\n",
       "          0.6364,  0.8906,  0.0503,  0.9924,  0.7113, -0.4222,  0.6597,  0.3169,\n",
       "         -0.8195,  0.7710,  0.8011,  0.5863, -0.1911, -0.0969, -0.9946,  0.9782,\n",
       "         -0.9081,  0.9172, -0.7912,  0.6616, -0.0479,  0.7361, -0.6688,  0.8858,\n",
       "         -0.9748,  0.3746,  0.9256, -0.9973,  0.6540,  0.7524,  0.7853, -0.0973,\n",
       "         -0.8788,  0.9908,  0.7555,  0.6950, -0.7217, -0.2862, -0.6684,  0.0615,\n",
       "         -0.9942,  0.9472, -0.8265, -0.9478,  0.8920,  0.9957, -0.5820,  0.6136,\n",
       "         -0.6773, -0.9663, -0.8980,  0.9056, -0.7448,  0.5031,  0.9599,  0.6518,\n",
       "          0.0510, -0.7140, -0.4352, -0.8027,  0.8333,  0.6754, -0.9139, -0.5860,\n",
       "         -0.4346, -0.6996, -0.4896,  0.9835, -0.8943,  0.6284,  0.7589, -0.7077,\n",
       "          0.7335, -0.3929, -0.9476,  0.9938, -0.9482,  0.8389, -0.7675,  0.8555,\n",
       "          0.7326, -0.8231, -0.9326,  0.7010, -0.7706,  0.1237,  0.6375, -0.5995,\n",
       "          0.9604, -0.9765, -0.6932,  0.7058, -0.6779, -0.9115, -0.4160,  0.1393,\n",
       "         -0.3460, -0.7230,  0.7524, -0.7738, -0.7545,  0.3338,  0.7970,  0.6814,\n",
       "          0.8957, -0.6732, -0.6156, -0.9563,  0.6118, -0.7704,  0.6966,  0.1860,\n",
       "         -0.5881,  0.7269,  0.7346, -0.1460,  0.5984,  0.7310,  0.1502, -0.3746,\n",
       "          0.5673,  0.7091, -0.0092,  0.9196,  0.9986,  0.8145, -0.4191, -0.7412]],\n",
       "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hubert-base-cc\n",
    "# Run time: 18m\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "model = AutoModel.from_pretrained(\"SZTAKI-HLT/hubert-base-cc\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"SZTAKI-HLT/hubert-base-cc\")\n",
    "\n",
    "get_avg_res(tokenizer,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9930734286141195\n"
     ]
    }
   ],
   "source": [
    "# mGPT\n",
    "# Run time: 234m\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sberbank-ai/mGPT\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"sberbank-ai/mGPT\")\n",
    "\n",
    "get_avg_res(tokenizer,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.060030954703928434\n"
     ]
    }
   ],
   "source": [
    "# sentiment-hts2-xlm-roberta-hungarian\n",
    "# Run time: 11m\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"NYTK/sentiment-hts2-xlm-roberta-hungarian\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"NYTK/sentiment-hts2-xlm-roberta-hungarian\")\n",
    "\n",
    "get_avg_res_sentiment(tokenizer,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7071057470567297\n"
     ]
    }
   ],
   "source": [
    "# sentiment-hts5-xlm-roberta-hungarian\n",
    "# Run time: 18m\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"NYTK/sentiment-hts5-xlm-roberta-hungarian\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"NYTK/sentiment-hts5-xlm-roberta-hungarian\")\n",
    "\n",
    "get_avg_res_sentiment(tokenizer,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49708486253667966\n"
     ]
    }
   ],
   "source": [
    "# sentiment-hts5-hubert-hungarian\n",
    "# Run time: 18m\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"NYTK/sentiment-hts5-hubert-hungarian\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"NYTK/sentiment-hts5-hubert-hungarian\")\n",
    "\n",
    "get_avg_res_sentiment(tokenizer,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.3236603515804651\n"
     ]
    }
   ],
   "source": [
    "# sentiment-hts2-hubert-hungarian\n",
    "# Run time: 17m\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"NYTK/sentiment-hts2-hubert-hungarian\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"NYTK/sentiment-hts2-hubert-hungarian\")\n",
    "\n",
    "get_avg_res_sentiment(tokenizer,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9970597336727028\n"
     ]
    }
   ],
   "source": [
    "# roberta-base\n",
    "# Run time: 22m\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "import torch\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "get_avg_res(tokenizer,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9956437026142038\n"
     ]
    }
   ],
   "source": [
    "# xlm-roberta-base\n",
    "# Run time: 43m\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"xlm-roberta-base\")\n",
    "\n",
    "get_avg_res(tokenizer,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9926321683722512\n"
     ]
    }
   ],
   "source": [
    "# xlm-roberta-large\n",
    "# Run time: 82m\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-large')\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"xlm-roberta-large\")\n",
    "\n",
    "get_avg_res(tokenizer,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMWithLMHeadModel were not initialized from the model checkpoint at xlm-mlm-100-1280 and are newly initialized: ['transformer.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6271096338710185\n"
     ]
    }
   ],
   "source": [
    "# xlm-mlm-100-1280\n",
    "# Run time: 109m\n",
    "from transformers import XLMTokenizer, XLMWithLMHeadModel\n",
    "import torch\n",
    "\n",
    "tokenizer = XLMTokenizer.from_pretrained(\"xlm-mlm-100-1280\")\n",
    "model = XLMWithLMHeadModel.from_pretrained(\"xlm-mlm-100-1280\")\n",
    "\n",
    "get_avg_res_xlm100(tokenizer,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.866267628416661\n"
     ]
    }
   ],
   "source": [
    "# xlm-roberta-xl\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "# xxl - 40G+\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/xlm-roberta-xl\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"facebook/xlm-roberta-xl\")\n",
    "\n",
    "get_avg_res(tokenizer,model)\n",
    "# 10 key dict - 8 min"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('errl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "c89ff4e902b8823068a4ef0519a72db2dea69528ae54c97e5cb904c57e44242d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
